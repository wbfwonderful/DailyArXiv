---
title: Latest 15 Papers - March 21, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Human-Centric Video Anomaly Detection Through Spatio-Temporal Pose Tokenization and Transformer](http://arxiv.org/abs/2408.15185v2)** | 2025-03-17 |  |
| **[Language-guided Open-world Video Anomaly Detection](http://arxiv.org/abs/2503.13160v1)** | 2025-03-17 |  |
| **[UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks](http://arxiv.org/abs/2503.12905v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted by AAAI 2025</p></details> |
| **[Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos](http://arxiv.org/abs/2503.07799v1)** | 2025-03-10 |  |
| **[Dual Conditioned Motion Diffusion for Pose-Based Video Anomaly Detection](http://arxiv.org/abs/2412.17210v2)** | 2025-03-08 | <details><summary>Code ...</summary><p>Code is on https://github.com/guijiejie/DCMD-main</p></details> |
| **[Video Anomaly Detection with Structured Keywords](http://arxiv.org/abs/2503.10653v1)** | 2025-03-07 |  |
| **[AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM](http://arxiv.org/abs/2503.04504v1)** | 2025-03-06 |  |
| **[Anomaly detection in non-stationary videos using time-recursive differencing network based prediction](http://arxiv.org/abs/2503.02234v1)** | 2025-03-04 | <details><summary>Copyr...</summary><p>Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Transformer Based Self-Context Aware Prediction for Few-Shot Anomaly Detection in Videos](http://arxiv.org/abs/2503.00670v1)** | 2025-03-02 | <details><summary>Copyr...</summary><p>Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion](http://arxiv.org/abs/2410.01506v4)** | 2025-02-28 | <details><summary>Accep...</summary><p>Accepted at the Thirteenth International Conference on Learning Representations (ICLR 2025)</p></details> |
| **[Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive LLM](http://arxiv.org/abs/2502.18863v1)** | 2025-02-26 |  |
| **[An Attribute-based Method for Video Anomaly Detection](http://arxiv.org/abs/2212.00789v2)** | 2025-01-26 | <details><summary>TMLR ...</summary><p>TMLR 2025. Our code is available at https://github.com/talreiss/Accurate-Interpretable-VAD</p></details> |
| **[Distilling Aggregated Knowledge for Weakly-Supervised Video Anomaly Detection](http://arxiv.org/abs/2406.02831v2)** | 2025-01-18 |  |
| **[ComplexVAD: Detecting Interaction Anomalies in Video](http://arxiv.org/abs/2501.09733v1)** | 2025-01-16 | <details><summary>16 pa...</summary><p>16 pages, 11 figures, to appear in WACV Workshop ASTAD 2025</p></details> |
| **[Detecting Contextual Anomalies by Discovering Consistent Spatial Regions](http://arxiv.org/abs/2501.08470v1)** | 2025-01-14 |  |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FAVOR-Bench: A Comprehensive Benchmark for Fine-Grained Video Motion Understanding](http://arxiv.org/abs/2503.14935v1)** | 2025-03-19 | <details><summary>FAVOR...</summary><p>FAVOR-Bench project page: https://favor-bench.github.io/</p></details> |
| **[Impossible Videos](http://arxiv.org/abs/2503.14378v1)** | 2025-03-18 | 26 pages |
| **[CaReBench: A Fine-Grained Benchmark for Video Captioning and Retrieval](http://arxiv.org/abs/2501.00513v2)** | 2025-03-18 |  |
| **[Zero-Shot Action Recognition in Surveillance Videos](http://arxiv.org/abs/2410.21113v2)** | 2025-03-18 |  |
| **[SpaceVLLM: Endowing Multimodal Large Language Model with Spatio-Temporal Video Grounding Capability](http://arxiv.org/abs/2503.13983v1)** | 2025-03-18 |  |
| **[Improving LLM Video Understanding with 16 Frames Per Second](http://arxiv.org/abs/2503.13956v1)** | 2025-03-18 |  |
| **[AdaCM$^2$: On Understanding Extremely Long-Term Video with Adaptive Cross-Modality Memory Reduction](http://arxiv.org/abs/2411.12593v2)** | 2025-03-18 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[Towards Scalable Modeling of Compressed Videos for Efficient Action Recognition](http://arxiv.org/abs/2503.13724v1)** | 2025-03-17 |  |
| **[Long-VMNet: Accelerating Long-Form Video Understanding via Fixed Memory](http://arxiv.org/abs/2503.13707v1)** | 2025-03-17 |  |
| **[VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning](http://arxiv.org/abs/2503.13444v1)** | 2025-03-17 | <details><summary>Proje...</summary><p>Project Page: https://videomind.github.io/</p></details> |
| **[Valley: Video Assistant with Large Language model Enhanced abilitY](http://arxiv.org/abs/2306.07207v3)** | 2025-03-17 |  |
| **[Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding](http://arxiv.org/abs/2503.13139v1)** | 2025-03-17 | <details><summary>18 pa...</summary><p>18 pages, under review</p></details> |
| **[Efficient Motion-Aware Video MLLM](http://arxiv.org/abs/2503.13016v1)** | 2025-03-17 | CVPR 2025 |
| **[Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation](http://arxiv.org/abs/2411.19951v4)** | 2025-03-17 | <details><summary>Proje...</summary><p>Project page: https://github.com/VITA-MLLM/Sparrow</p></details> |
| **[VideoScan: Enabling Efficient Streaming Video Understanding via Frame-level Semantic Carriers](http://arxiv.org/abs/2503.09387v2)** | 2025-03-17 | 11 pages, 4 figures |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TULIP: Towards Unified Language-Image Pretraining](http://arxiv.org/abs/2503.15485v1)** | 2025-03-19 |  |
| **[Visual Persona: Foundation Model for Full-Body Human Customization](http://arxiv.org/abs/2503.15406v1)** | 2025-03-19 | <details><summary>CVPR ...</summary><p>CVPR 2025, Project page is available at https://cvlab-kaist.github.io/Visual-Persona</p></details> |
| **[Safety at Scale: A Comprehensive Survey of Large Model Safety](http://arxiv.org/abs/2502.05206v3)** | 2025-03-19 | <details><summary>47 pa...</summary><p>47 pages, 3 figures, 11 tables; GitHub: https://github.com/xingjunm/Awesome-Large-Model-Safety</p></details> |
| **[EfficientLLaVA:Generalizable Auto-Pruning for Large Vision-language Models](http://arxiv.org/abs/2503.15369v1)** | 2025-03-19 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025</p></details> |
| **[SemEval-2025 Task 1: AdMIRe -- Advancing Multimodal Idiomaticity Representation](http://arxiv.org/abs/2503.15358v1)** | 2025-03-19 | <details><summary>Prepr...</summary><p>Preprint; SemEval-2025 proceedings to appear at ACL 2025</p></details> |
| **[TruthLens:A Training-Free Paradigm for DeepFake Detection](http://arxiv.org/abs/2503.15342v1)** | 2025-03-19 |  |
| **[Recover and Match: Open-Vocabulary Multi-Label Recognition through Knowledge-Constrained Optimal Transport](http://arxiv.org/abs/2503.15337v1)** | 2025-03-19 | CVPR 2025 |
| **[MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning](http://arxiv.org/abs/2502.19634v2)** | 2025-03-19 |  |
| **[Paint by Inpaint: Learning to Add Image Objects by Removing Them First](http://arxiv.org/abs/2404.18212v2)** | 2025-03-19 |  |
| **[A Unified Framework for Real-Time Failure Handling in Robotics Using Vision-Language Models, Reactive Planner and Behavior Trees](http://arxiv.org/abs/2503.15202v1)** | 2025-03-19 |  |
| **[Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU](http://arxiv.org/abs/2503.15166v1)** | 2025-03-19 | Preprint |
| **[FiVL: A Framework for Improved Vision-Language Alignment through the Lens of Training, Evaluation and Explainability](http://arxiv.org/abs/2412.14672v2)** | 2025-03-19 |  |
| **[Post-hoc Probabilistic Vision-Language Models](http://arxiv.org/abs/2412.06014v2)** | 2025-03-19 | <details><summary>Proje...</summary><p>Project page: https://aaltoml.github.io/BayesVLM/</p></details> |
| **[VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making](http://arxiv.org/abs/2503.15108v1)** | 2025-03-19 |  |
| **[MMLNB: Multi-Modal Learning for Neuroblastoma Subtyping Classification Assisted with Textual Description Generation](http://arxiv.org/abs/2503.12927v2)** | 2025-03-19 | 25 pages, 7 figures |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding](http://arxiv.org/abs/2410.11761v3)** | 2025-03-19 | Accepted by CVPR2025 |
| **[Visual Position Prompt for MLLM based Visual Grounding](http://arxiv.org/abs/2503.15426v1)** | 2025-03-19 |  |
| **[Creation-MMBench: Assessing Context-Aware Creative Intelligence in MLLM](http://arxiv.org/abs/2503.14478v2)** | 2025-03-19 | <details><summary>Evalu...</summary><p>Evaluation Code and dataset see https://github.com/open-compass/Creation-MMBench</p></details> |
| **[EfficientLLaVA:Generalizable Auto-Pruning for Large Vision-language Models](http://arxiv.org/abs/2503.15369v1)** | 2025-03-19 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025</p></details> |
| **[LEGION: Learning to Ground and Explain for Synthetic Image Detection](http://arxiv.org/abs/2503.15264v1)** | 2025-03-19 | <details><summary>Proje...</summary><p>Project Page: https://opendatalab.github.io/LEGION</p></details> |
| **[Benchmarking Large Language Models for Handwritten Text Recognition](http://arxiv.org/abs/2503.15195v1)** | 2025-03-19 |  |
| **[Towards Self-Improving Systematic Cognition for Next-Generation Foundation MLLMs](http://arxiv.org/abs/2503.12303v3)** | 2025-03-19 | <details><summary>38 pa...</summary><p>38 pages. Preprint, work in progress</p></details> |
| **[ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area](http://arxiv.org/abs/2408.07246v4)** | 2025-03-19 | <details><summary>11 pa...</summary><p>11 pages, updated version</p></details> |
| **[Towards Understanding the Safety Boundaries of DeepSeek Models: Evaluation and Findings](http://arxiv.org/abs/2503.15092v1)** | 2025-03-19 |  |
| **[DocLayLLM: An Efficient Multi-modal Extension of Large Language Models for Text-rich Document Understanding](http://arxiv.org/abs/2408.15045v3)** | 2025-03-19 | CVPR2025 |
| **[LLaVA-UHD v2: an MLLM Integrating High-Resolution Semantic Pyramid via Hierarchical Window Transformer](http://arxiv.org/abs/2412.13871v2)** | 2025-03-19 |  |
| **[UPME: An Unsupervised Peer Review Framework for Multimodal Large Language Model Evaluation](http://arxiv.org/abs/2503.14941v1)** | 2025-03-19 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025</p></details> |
| **[VisNumBench: Evaluating Number Sense of Multimodal Large Language Models](http://arxiv.org/abs/2503.14939v1)** | 2025-03-19 |  |
| **[FAVOR-Bench: A Comprehensive Benchmark for Fine-Grained Video Motion Understanding](http://arxiv.org/abs/2503.14935v1)** | 2025-03-19 | <details><summary>FAVOR...</summary><p>FAVOR-Bench project page: https://favor-bench.github.io/</p></details> |
| **[Unveiling the Ignorance of MLLMs: Seeing Clearly, Answering Incorrectly](http://arxiv.org/abs/2406.10638v3)** | 2025-03-19 |  |

