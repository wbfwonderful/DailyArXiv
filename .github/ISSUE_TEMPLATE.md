---
title: Latest 15 Papers - May 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](http://arxiv.org/abs/2505.02393v2)** | 2025-05-08 |  |
| **[ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications](http://arxiv.org/abs/2505.02179v1)** | 2025-05-04 |  |
| **[Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving](http://arxiv.org/abs/2406.06423v3)** | 2025-04-28 | <details><summary>Danie...</summary><p>Daniel Bogdoll and Jan Imhof contributed equally. Accepted for publication at BMVC 2024 RROW workshop. Won Best Paper Award</p></details> |
| **[Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches](http://arxiv.org/abs/2504.14753v1)** | 2025-04-20 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Image Processing (TIP)</p></details> |
| **[EventVAD: Training-Free Event-Aware Video Anomaly Detection](http://arxiv.org/abs/2504.13092v1)** | 2025-04-17 |  |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |
| **[AssistPDA: An Online Video Surveillance Assistant for Video Anomaly Prediction, Detection, and Analysis](http://arxiv.org/abs/2503.21904v1)** | 2025-03-27 | 13 pages |
| **[VADMamba: Exploring State Space Models for Fast Video Anomaly Detection](http://arxiv.org/abs/2503.21169v1)** | 2025-03-27 | <details><summary>Accpe...</summary><p>Accpeted by ICME 2025</p></details> |
| **[Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection](http://arxiv.org/abs/2412.03044v2)** | 2025-03-27 |  |
| **[Video Anomaly Detection with Contours -- A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation](http://arxiv.org/abs/2505.08665v1)** | 2025-05-13 |  |
| **[VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large Video Language Models](http://arxiv.org/abs/2505.08455v1)** | 2025-05-13 |  |
| **[SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding](http://arxiv.org/abs/2504.21435v3)** | 2025-05-13 | <details><summary>29 pa...</summary><p>29 pages, 15 figures, CVPR 2025</p></details> |
| **[HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding](http://arxiv.org/abs/2501.01645v3)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted to ICME 2025</p></details> |
| **[An Analysis of Data Transformation Effects on Segment Anything 2](http://arxiv.org/abs/2503.00042v2)** | 2025-05-13 | 11 pages, 30 figures |
| **[A SAT-centered XAI method for Deep Learning based Video Understanding](http://arxiv.org/abs/2503.23870v2)** | 2025-05-12 |  |
| **[Gameplay Highlights Generation](http://arxiv.org/abs/2505.07721v1)** | 2025-05-12 |  |
| **[Seed1.5-VL Technical Report](http://arxiv.org/abs/2505.07062v1)** | 2025-05-11 |  |
| **[Overview of the NLPCC 2025 Shared Task 4: Multi-modal, Multilingual, and Multi-hop Medical Instructional Video Question Answering Challenge](http://arxiv.org/abs/2505.06814v1)** | 2025-05-11 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 4 tables</p></details> |
| **[DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs](http://arxiv.org/abs/2504.17040v2)** | 2025-05-10 |  |
| **[Egocentric and Exocentric Methods: A Short Survey](http://arxiv.org/abs/2410.20621v2)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted in Computer Vision and Image Understanding (CVIU), 2025</p></details> |
| **[StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](http://arxiv.org/abs/2505.05467v1)** | 2025-05-08 |  |
| **[Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](http://arxiv.org/abs/2505.02393v2)** | 2025-05-08 |  |
| **[3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark](http://arxiv.org/abs/2412.07825v3)** | 2025-05-08 | <details><summary>Proje...</summary><p>Project page: https://3dsrbench.github.io</p></details> |
| **[AffectGPT: A New Dataset, Model, and Benchmark for Emotion Understanding with Multimodal Large Language Models](http://arxiv.org/abs/2501.16566v2)** | 2025-05-07 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models](http://arxiv.org/abs/2505.10526v1)** | 2025-05-15 | <details><summary>Main ...</summary><p>Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp</p></details> |
| **[Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](http://arxiv.org/abs/2504.17671v3)** | 2025-05-15 | <details><summary>Accep...</summary><p>Accepted by ICIPCA 2025</p></details> |
| **[AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge](http://arxiv.org/abs/2505.10468v1)** | 2025-05-15 | <details><summary>32 pa...</summary><p>32 pages, 14 figures, 11 tables</p></details> |
| **[Vision language models have difficulty recognizing virtual objects](http://arxiv.org/abs/2505.10453v1)** | 2025-05-15 |  |
| **[WildFireCan-MMD: A Multimodal Dataset for Classification of User-Generated Content During Wildfires in Canada](http://arxiv.org/abs/2504.13231v2)** | 2025-05-15 |  |
| **[MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models](http://arxiv.org/abs/2505.10088v1)** | 2025-05-15 | <details><summary>Due t...</summary><p>Due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract appearing here is slightly shorter than that in the PDF file</p></details> |
| **[Behind Maya: Building a Multilingual Vision Language Model](http://arxiv.org/abs/2505.08910v2)** | 2025-05-15 | <details><summary>Accep...</summary><p>Accepted at VLMs4ALL CVPR 2025 Workshop; corrected workshop name spelling</p></details> |
| **[AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection](http://arxiv.org/abs/2505.09926v1)** | 2025-05-15 | <details><summary>27 pa...</summary><p>27 pages, 15 figures, 22 tables</p></details> |
| **[Unfettered Forceful Skill Acquisition with Physical Reasoning and Coordinate Frame Labeling](http://arxiv.org/abs/2505.09731v1)** | 2025-05-14 |  |
| **[ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation](http://arxiv.org/abs/2505.09698v1)** | 2025-05-14 | <details><summary>47 pa...</summary><p>47 pages, 29 figures. Under review</p></details> |
| **[Variational Visual Question Answering](http://arxiv.org/abs/2505.09591v1)** | 2025-05-14 | <details><summary>19 pa...</summary><p>19 pages, 16 figures, under review at ICCV 2025</p></details> |
| **[VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation](http://arxiv.org/abs/2505.09577v1)** | 2025-05-14 |  |
| **[Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput](http://arxiv.org/abs/2505.09498v1)** | 2025-05-14 | 18 pages, 7 figures |
| **[MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification](http://arxiv.org/abs/2502.07409v3)** | 2025-05-14 |  |
| **[Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition](http://arxiv.org/abs/2505.09336v1)** | 2025-05-14 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis](http://arxiv.org/abs/2505.10541v1)** | 2025-05-15 |  |
| **[Unified Modeling Language Code Generation from Diagram Images Using Multimodal Large Language Models](http://arxiv.org/abs/2503.12293v2)** | 2025-05-15 | <details><summary>Publi...</summary><p>Published in the Journal of Machine Learning with Applications, Author Contributions: Averi Bates: Methodology, Development, Analysis, Data Curation, Drafting, Review. Ryan Vavricka: Data Curation, Development, Review. Shane Carleton: Supervision, Funding. Ruosi Shao: Review. Chongle Pan: Supervision, Review</p></details> |
| **[Scaling Laws for Black box Adversarial Attacks](http://arxiv.org/abs/2411.16782v2)** | 2025-05-15 |  |
| **[Video-R1: Reinforcing Video Reasoning in MLLMs](http://arxiv.org/abs/2503.21776v3)** | 2025-05-15 | <details><summary>Proje...</summary><p>Project page: https://github.com/tulerfeng/Video-R1</p></details> |
| **[CartoAgent: a multimodal large language model-powered multi-agent cartographic framework for map style transfer and evaluation](http://arxiv.org/abs/2505.09936v1)** | 2025-05-15 | 57 pages, 17 figures |
| **[UICopilot: Automating UI Synthesis via Hierarchical Code Generation from Webpage Designs](http://arxiv.org/abs/2505.09904v1)** | 2025-05-15 | WWW' 2025 |
| **[A Multimodal Multi-Agent Framework for Radiology Report Generation](http://arxiv.org/abs/2505.09787v1)** | 2025-05-14 |  |
| **[FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models](http://arxiv.org/abs/2505.09415v1)** | 2025-05-14 |  |
| **[UI-R1: Enhancing Efficient Action Prediction of GUI Agents by Reinforcement Learning](http://arxiv.org/abs/2503.21620v4)** | 2025-05-14 | Updated UI-R1-E-3B |
| **[AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection](http://arxiv.org/abs/2505.09155v1)** | 2025-05-14 | accepted by LAD25 |
| **[Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts](http://arxiv.org/abs/2505.08838v1)** | 2025-05-13 |  |
| **[HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding](http://arxiv.org/abs/2501.01645v3)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted to ICME 2025</p></details> |
| **[MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation](http://arxiv.org/abs/2410.13757v3)** | 2025-05-13 | <details><summary>NAACL...</summary><p>NAACL 2025 Demo Track [code] https://github.com/OpenDFM/MobA [dataset] https://huggingface.co/datasets/OpenDFM/MobA-MobBench</p></details> |
| **[Visually Interpretable Subtask Reasoning for Visual Question Answering](http://arxiv.org/abs/2505.08084v1)** | 2025-05-12 |  |
| **[SCA: Improve Semantic Consistent in Unrestricted Adversarial Attacks via DDPM Inversion](http://arxiv.org/abs/2410.02240v6)** | 2025-05-12 |  |

