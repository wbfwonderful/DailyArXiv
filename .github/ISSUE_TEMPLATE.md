---
title: Latest 15 Papers - November 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Video Anomaly Detection for Smart Surveillance](https://arxiv.org/pdf/2004.00222v3)** | 2020-04-14 |  |
| **[ComplexVAD: Detecting Interaction Anomalies in Video](https://arxiv.org/pdf/2501.09733v1)** | 2025-01-17 | <details><summary>16 pa...</summary><p>16 pages, 11 figures, to appear in WACV Workshop ASTAD 2025</p></details> |
| **[Open-Vocabulary Video Anomaly Detection](https://arxiv.org/pdf/2311.07042v3)** | 2024-03-14 | Accepted to CVPR2024 |
| **[ADNet: Temporal Anomaly Detection in Surveillance Videos](https://arxiv.org/pdf/2104.06653v1)** | 2021-04-15 | <details><summary>FGVRI...</summary><p>FGVRID workshop of ICPR conference, 15 pages</p></details> |
| **[Deep Video Anomaly Detection: Opportunities and Challenges](https://arxiv.org/pdf/2110.05086v1)** | 2021-10-12 | 8 pages, 2 figures |
| **[Dynamic Distinction Learning: Adaptive Pseudo Anomalies for Video Anomaly Detection](https://arxiv.org/pdf/2404.04986v1)** | 2024-04-09 | <details><summary>To be...</summary><p>To be published in the CVPR2024 Workshop</p></details> |
| **[Overlooked Video Classification in Weakly Supervised Video Anomaly Detection](https://arxiv.org/pdf/2210.06688v2)** | 2023-04-21 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2101.10030 by other authors</p></details> |
| **[Visual anomaly detection in video by variational autoencoder](https://arxiv.org/pdf/2203.03872v1)** | 2022-03-09 |  |
| **[A Modular and Unified Framework for Detecting and Localizing Video Anomalies](https://arxiv.org/pdf/2103.11299v1)** | 2021-03-23 |  |
| **[Video Anomaly Detection with Contours -- A Study](https://arxiv.org/pdf/2503.19588v1)** | 2025-03-30 |  |
| **[Anomaly Detection in Video Sequences: A Benchmark and Computational Model](https://arxiv.org/pdf/2106.08570v1)** | 2021-06-17 | <details><summary>Publi...</summary><p>Publication in IET Image Processing</p></details> |
| **[Approaches Toward Physical and General Video Anomaly Detection](https://arxiv.org/pdf/2112.07661v1)** | 2021-12-15 |  |
| **[Real-world Anomaly Detection in Surveillance Videos](https://arxiv.org/pdf/1801.04264v3)** | 2019-02-15 |  |
| **[Video Anomaly Detection with Structured Keywords](https://arxiv.org/pdf/2503.10653v1)** | 2025-03-17 |  |
| **[Adversarial Machine Learning Attacks Against Video Anomaly Detection Systems](https://arxiv.org/pdf/2204.03141v1)** | 2022-04-08 |  |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Revisiting the "Video" in Video-Language Understanding](https://arxiv.org/pdf/2206.01720v1)** | 2022-06-06 | CVPR 2022 (Oral) |
| **[Video Action Understanding](https://arxiv.org/pdf/2010.06647v2)** | 2021-10-05 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Access</p></details> |
| **[Infinite Video Understanding](https://arxiv.org/pdf/2507.09068v2)** | 2025-07-24 |  |
| **[Long Video Understanding with Learnable Retrieval in Video-Language Models](https://arxiv.org/pdf/2312.04931v3)** | 2025-09-25 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Multimedia (TMM)</p></details> |
| **[Omni-Video: Democratizing Unified Video Understanding and Generation](https://arxiv.org/pdf/2507.06119v3)** | 2025-08-22 | <details><summary>Techn...</summary><p>Technical report, project page: https://howellyoung-s.github.io/OmniVideo_project/</p></details> |
| **[Video Panels for Long Video Understanding](https://arxiv.org/pdf/2509.23724v1)** | 2025-09-30 |  |
| **[Q-Bench-Video: Benchmarking the Video Quality Understanding of LMMs](https://arxiv.org/pdf/2409.20063v2)** | 2025-03-04 |  |
| **[VideoChat: Chat-Centric Video Understanding](https://arxiv.org/pdf/2305.06355v2)** | 2024-01-05 | Technical report |
| **[TinyLLaVA-Video: Towards Smaller LMMs for Video Understanding with Group Resampler](https://arxiv.org/pdf/2501.15513v2)** | 2025-06-11 | <details><summary>code ...</summary><p>code and training recipes are available at https://github.com/ZhangXJ199/TinyLLaVA-Video</p></details> |
| **[VUDG: A Dataset for Video Understanding Domain Generalization](https://arxiv.org/pdf/2505.24346v1)** | 2025-06-02 |  |
| **[VideoGPT+: Integrating Image and Video Encoders for Enhanced Video Understanding](https://arxiv.org/pdf/2406.09418v1)** | 2024-06-14 | Technical Report |
| **[VCA: Video Curious Agent for Long Video Understanding](https://arxiv.org/pdf/2412.10471v2)** | 2025-03-11 |  |
| **[ALLVB: All-in-One Long Video Understanding Benchmark](https://arxiv.org/pdf/2503.07298v2)** | 2025-04-02 | AAAI 2025 |
| **[Query-aware Long Video Localization and Relation Discrimination for Deep Video Understanding](https://arxiv.org/pdf/2310.12724v1)** | 2023-10-20 | <details><summary>ACM M...</summary><p>ACM MM 2023 Grand Challenge</p></details> |
| **[Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought](https://arxiv.org/pdf/2506.08817v3)** | 2025-06-13 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Assessing Color Vision Test in Large Vision-language Models](https://arxiv.org/pdf/2507.11153v1)** | 2025-07-16 |  |
| **[Vision-and-Language Pretrained Models: A Survey](https://arxiv.org/pdf/2204.07356v5)** | 2022-05-05 | <details><summary>Accep...</summary><p>Accepted in IJCAI 2022</p></details> |
| **[Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks](https://arxiv.org/pdf/2301.05065v2)** | 2023-10-18 |  |
| **[Unveiling Encoder-Free Vision-Language Models](https://arxiv.org/pdf/2406.11832v2)** | 2024-10-30 | <details><summary>17 pa...</summary><p>17 pages, 8 figures, Accepted by NeurIPS2024 (spotlight)</p></details> |
| **[FLAVA: A Foundational Language And Vision Alignment Model](https://arxiv.org/pdf/2112.04482v3)** | 2022-03-31 | CVPR 2022 |
| **[HiMix: Reducing Computational Complexity in Large Vision-Language Models](https://arxiv.org/pdf/2501.10318v1)** | 2025-01-20 |  |
| **[An Introduction to Vision-Language Modeling](https://arxiv.org/pdf/2405.17247v1)** | 2024-05-28 |  |
| **[Uncertainty-Aware Evaluation for Vision-Language Models](https://arxiv.org/pdf/2402.14418v2)** | 2024-02-27 |  |
| **[Evaluating Attribute Comprehension in Large Vision-Language Models](https://arxiv.org/pdf/2408.13898v1)** | 2024-08-27 | 15 pages, 4 figures |
| **[On the Domain Robustness of Contrastive Vision-Language Models](https://arxiv.org/pdf/2506.23663v1)** | 2025-07-01 | <details><summary>Deepb...</summary><p>Deepbench is available at https://github.com/ml-lab-htw/deepbench</p></details> |
| **[HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding](https://arxiv.org/pdf/2412.16158v2)** | 2025-02-11 |  |
| **[A Review of 3D Object Detection with Vision-Language Models](https://arxiv.org/pdf/2504.18738v1)** | 2025-04-29 |  |
| **[Vision-Language Foundation Models as Effective Robot Imitators](https://arxiv.org/pdf/2311.01378v3)** | 2024-02-06 | <details><summary>Fix t...</summary><p>Fix typos. Project page: https://roboflamingo.github.io</p></details> |
| **[CoLLaVO: Crayon Large Language and Vision mOdel](https://arxiv.org/pdf/2402.11248v4)** | 2024-06-04 | <details><summary>ACL 2...</summary><p>ACL 2024 Findings. Code available: https://github.com/ByungKwanLee/CoLLaVO</p></details> |
| **[HyperCLIP: Adapting Vision-Language models with Hypernetworks](https://arxiv.org/pdf/2412.16777v1)** | 2024-12-24 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Survey on Multimodal Large Language Models](https://arxiv.org/pdf/2306.13549v4)** | 2024-12-02 | <details><summary>Accep...</summary><p>Accepted for publication in National Science Review. Project page:https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models</p></details> |
| **[LaVy: Vietnamese Multimodal Large Language Model](https://arxiv.org/pdf/2404.07922v6)** | 2024-07-17 | 5 pages |
| **[Multimodal Large Language Models: A Survey](https://arxiv.org/pdf/2311.13165v1)** | 2023-11-23 | <details><summary>IEEE ...</summary><p>IEEE BigData 2023. 10 pages</p></details> |
| **[Multimodal Large Language Models and Tunings: Vision, Language, Sensors, Audio, and Beyond](https://arxiv.org/pdf/2410.05608v1)** | 2024-10-10 | <details><summary>Accep...</summary><p>Accepted at ACM-MM 2024</p></details> |
| **[Embracing Large Language and Multimodal Models for Prosthetic Technologies](https://arxiv.org/pdf/2403.04974v2)** | 2024-03-12 |  |
| **[Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench](https://arxiv.org/pdf/2410.22108v2)** | 2025-02-18 | NAACL Main 2025 |
| **[Personalized Multimodal Large Language Models: A Survey](https://arxiv.org/pdf/2412.02142v1)** | 2024-12-04 |  |
| **[Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages](https://arxiv.org/pdf/2308.12038v3)** | 2024-03-25 | <details><summary>https...</summary><p>https://github.com/OpenBMB/VisCPM.git</p></details> |
| **[OCC-MLLM:Empowering Multimodal Large Language Model For the Understanding of Occluded Objects](https://arxiv.org/pdf/2410.01261v1)** | 2024-10-03 | <details><summary>Accep...</summary><p>Accepted by CVPR 2024 T4V Workshop (5 pages, 3 figures, 2 tables)</p></details> |
| **[A Survey on Multimodal Large Language Models for Autonomous Driving](https://arxiv.org/pdf/2311.12320v1)** | 2023-11-22 |  |
| **[ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area](https://arxiv.org/pdf/2408.07246v6)** | 2025-10-28 | <details><summary>11 pa...</summary><p>11 pages, updated version</p></details> |
| **[Speculative Decoding Reimagined for Multimodal Large Language Models](https://arxiv.org/pdf/2505.14260v1)** | 2025-05-21 | 12 pages |
| **[E5-V: Universal Embeddings with Multimodal Large Language Models](https://arxiv.org/pdf/2407.12580v1)** | 2024-07-18 | <details><summary>Code ...</summary><p>Code and models are available at https://github.com/kongds/E5-V</p></details> |
| **[Leveraging Large Language Models for Multimodal Search](https://arxiv.org/pdf/2404.15790v1)** | 2024-04-25 | <details><summary>Publi...</summary><p>Published at CVPRW 2024</p></details> |
| **[Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org/pdf/2504.16427v2)** | 2025-04-25 | 23 pages, 5 figures |

