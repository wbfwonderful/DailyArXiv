---
title: Latest 15 Papers - April 16, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |
| **[AssistPDA: An Online Video Surveillance Assistant for Video Anomaly Prediction, Detection, and Analysis](http://arxiv.org/abs/2503.21904v1)** | 2025-03-27 | 13 pages |
| **[VADMamba: Exploring State Space Models for Fast Video Anomaly Detection](http://arxiv.org/abs/2503.21169v1)** | 2025-03-27 | <details><summary>Accpe...</summary><p>Accpeted by ICME 2025</p></details> |
| **[Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection](http://arxiv.org/abs/2412.03044v2)** | 2025-03-27 |  |
| **[Video Anomaly Detection with Contours -- A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |
| **[Anomize: Better Open Vocabulary Video Anomaly Detection](http://arxiv.org/abs/2503.18094v1)** | 2025-03-23 |  |
| **[Towards Adaptive Human-centric Video Anomaly Detection: A Comprehensive Framework and A New Benchmark](http://arxiv.org/abs/2408.14329v2)** | 2025-03-19 |  |
| **[Human-Centric Video Anomaly Detection Through Spatio-Temporal Pose Tokenization and Transformer](http://arxiv.org/abs/2408.15185v2)** | 2025-03-17 |  |
| **[Language-guided Open-world Video Anomaly Detection](http://arxiv.org/abs/2503.13160v1)** | 2025-03-17 |  |
| **[UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks](http://arxiv.org/abs/2503.12905v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted by AAAI 2025</p></details> |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Multimodal Long Video Modeling Based on Temporal Dynamic Context](http://arxiv.org/abs/2504.10443v1)** | 2025-04-14 |  |
| **[Mavors: Multi-granularity Video Representation for Multimodal Large Language Model](http://arxiv.org/abs/2504.10068v1)** | 2025-04-14 | 22 pages |
| **[TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning](http://arxiv.org/abs/2504.09641v1)** | 2025-04-13 |  |
| **[MM-Ego: Towards Building Egocentric Multimodal LLMs for Video QA](http://arxiv.org/abs/2410.07177v2)** | 2025-04-13 | <details><summary>Accep...</summary><p>Accepted by ICLR 2025</p></details> |
| **[VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning](http://arxiv.org/abs/2504.06958v3)** | 2025-04-13 |  |
| **[VideoAds for Fast-Paced Video Understanding: Where Opensource Foundation Models Beat GPT-4o & Gemini-1.5 Pro](http://arxiv.org/abs/2504.09282v1)** | 2025-04-12 |  |
| **[Towards Efficient and Robust Moment Retrieval System: A Unified Framework for Multi-Granularity Models and Temporal Reranking](http://arxiv.org/abs/2504.08384v1)** | 2025-04-11 |  |
| **[SpaceVLLM: Endowing Multimodal Large Language Model with Spatio-Temporal Video Grounding Capability](http://arxiv.org/abs/2503.13983v3)** | 2025-04-11 |  |
| **[F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos](http://arxiv.org/abs/2504.08222v1)** | 2025-04-11 | <details><summary>The T...</summary><p>The Thirteenth International Conference on Learning Representations (ICLR 2025)</p></details> |
| **[SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding](http://arxiv.org/abs/2504.07745v1)** | 2025-04-10 | Accepted to CVPR2025 |
| **[VideoExpert: Augmented LLM for Temporal-Sensitive Video Understanding](http://arxiv.org/abs/2504.07519v1)** | 2025-04-10 |  |
| **[How Can Objects Help Video-Language Understanding?](http://arxiv.org/abs/2504.07454v1)** | 2025-04-10 |  |
| **[LVC: A Lightweight Compression Framework for Enhancing VLMs in Long Video Understanding](http://arxiv.org/abs/2504.06835v1)** | 2025-04-09 |  |
| **[AuroraCap: Efficient, Performant Video Detailed Captioning and a New Benchmark](http://arxiv.org/abs/2410.03051v4)** | 2025-04-09 | <details><summary>Accep...</summary><p>Accepted to ICLR 2025. Code, docs, weight, benchmark and training data are all avaliable at https://rese1f.github.io/aurora-web/</p></details> |
| **[From Broadcast to Minimap: Achieving State-of-the-Art SoccerNet Game State Reconstruction](http://arxiv.org/abs/2504.06357v1)** | 2025-04-08 | <details><summary>Accep...</summary><p>Accepted for presentation at the CVPR 2025 CVsports Workshop</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding](http://arxiv.org/abs/2504.10465v1)** | 2025-04-14 |  |
| **[GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents](http://arxiv.org/abs/2504.10458v1)** | 2025-04-14 |  |
| **[Learning Free Token Reduction for Multi-Modal Large Language Models](http://arxiv.org/abs/2501.17391v2)** | 2025-04-14 |  |
| **[ITACLIP: Boosting Training-Free Semantic Segmentation with Image, Text, and Architectural Enhancements](http://arxiv.org/abs/2411.12044v2)** | 2025-04-14 |  |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model](http://arxiv.org/abs/2504.07615v2)** | 2025-04-14 | <details><summary>11 pa...</summary><p>11 pages, fix some minor typos in the previous version</p></details> |
| **[ResiDual Transformer Alignment with Spectral Decomposition](http://arxiv.org/abs/2411.00246v2)** | 2025-04-14 | <details><summary>Publi...</summary><p>Published in Transactions on Machine Learning Research (TMLR)</p></details> |
| **[Frequency Is What You Need: Word-frequency Masking Benefits Vision-Language Model Pre-training](http://arxiv.org/abs/2412.16148v2)** | 2025-04-14 |  |
| **[Breaking the Data Barrier -- Building GUI Agents Through Task Generalization](http://arxiv.org/abs/2504.10127v1)** | 2025-04-14 | 24 pages, 11 figures |
| **[AGO: Adaptive Grounding for Open World 3D Occupancy Prediction](http://arxiv.org/abs/2504.10117v1)** | 2025-04-14 |  |
| **[CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography](http://arxiv.org/abs/2504.10090v1)** | 2025-04-14 |  |
| **[Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure](http://arxiv.org/abs/2504.10049v1)** | 2025-04-14 |  |
| **[Aligning Anime Video Generation with Human Feedback](http://arxiv.org/abs/2504.10044v1)** | 2025-04-14 | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 7 tables</p></details> |
| **[KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks](http://arxiv.org/abs/2504.10011v1)** | 2025-04-14 | <details><summary>17 pa...</summary><p>17 pages, Submitted to IEEE Access April 9th 2025</p></details> |
| **[GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control](http://arxiv.org/abs/2504.09997v1)** | 2025-04-14 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models](http://arxiv.org/abs/2504.10479v1)** | 2025-04-14 | Technical Report |
| **[MIEB: Massive Image Embedding Benchmark](http://arxiv.org/abs/2504.10471v1)** | 2025-04-14 |  |
| **[Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding](http://arxiv.org/abs/2504.10465v1)** | 2025-04-14 |  |
| **[The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer](http://arxiv.org/abs/2504.10462v1)** | 2025-04-14 |  |
| **[Learning Free Token Reduction for Multi-Modal Large Language Models](http://arxiv.org/abs/2501.17391v2)** | 2025-04-14 |  |
| **[VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge](http://arxiv.org/abs/2504.10342v1)** | 2025-04-14 | 56 pages, 43 figures |
| **[PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam Annealing Search](http://arxiv.org/abs/2504.10222v1)** | 2025-04-14 |  |
| **[The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance](http://arxiv.org/abs/2504.10179v1)** | 2025-04-14 |  |
| **[COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts](http://arxiv.org/abs/2504.10158v1)** | 2025-04-14 |  |
| **[PhD: A ChatGPT-Prompted Visual hallucination Evaluation Dataset](http://arxiv.org/abs/2403.11116v4)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025, Highlight</p></details> |
| **[MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation](http://arxiv.org/abs/2503.20384v2)** | 2025-04-14 |  |
| **[CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography](http://arxiv.org/abs/2504.10090v1)** | 2025-04-14 |  |
| **[Mavors: Multi-granularity Video Representation for Multimodal Large Language Model](http://arxiv.org/abs/2504.10068v1)** | 2025-04-14 | 22 pages |
| **[The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination](http://arxiv.org/abs/2504.10020v1)** | 2025-04-14 |  |
| **[FUSION: Fully Integration of Vision-Language Representations for Deep Cross-Modal Understanding](http://arxiv.org/abs/2504.09925v1)** | 2025-04-14 |  |

