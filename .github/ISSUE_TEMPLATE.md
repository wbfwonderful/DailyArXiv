---
title: Latest 15 Papers - May 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](http://arxiv.org/abs/2505.02393v2)** | 2025-05-08 |  |
| **[ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications](http://arxiv.org/abs/2505.02179v1)** | 2025-05-04 |  |
| **[Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving](http://arxiv.org/abs/2406.06423v3)** | 2025-04-28 | <details><summary>Danie...</summary><p>Daniel Bogdoll and Jan Imhof contributed equally. Accepted for publication at BMVC 2024 RROW workshop. Won Best Paper Award</p></details> |
| **[Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches](http://arxiv.org/abs/2504.14753v1)** | 2025-04-20 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Image Processing (TIP)</p></details> |
| **[EventVAD: Training-Free Event-Aware Video Anomaly Detection](http://arxiv.org/abs/2504.13092v1)** | 2025-04-17 |  |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |
| **[AssistPDA: An Online Video Surveillance Assistant for Video Anomaly Prediction, Detection, and Analysis](http://arxiv.org/abs/2503.21904v1)** | 2025-03-27 | 13 pages |
| **[VADMamba: Exploring State Space Models for Fast Video Anomaly Detection](http://arxiv.org/abs/2503.21169v1)** | 2025-03-27 | <details><summary>Accpe...</summary><p>Accpeted by ICME 2025</p></details> |
| **[Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection](http://arxiv.org/abs/2412.03044v2)** | 2025-03-27 |  |
| **[Video Anomaly Detection with Contours -- A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation](http://arxiv.org/abs/2505.08665v1)** | 2025-05-13 |  |
| **[VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large Video Language Models](http://arxiv.org/abs/2505.08455v1)** | 2025-05-13 |  |
| **[SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding](http://arxiv.org/abs/2504.21435v3)** | 2025-05-13 | <details><summary>29 pa...</summary><p>29 pages, 15 figures, CVPR 2025</p></details> |
| **[HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding](http://arxiv.org/abs/2501.01645v3)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted to ICME 2025</p></details> |
| **[An Analysis of Data Transformation Effects on Segment Anything 2](http://arxiv.org/abs/2503.00042v2)** | 2025-05-13 | 11 pages, 30 figures |
| **[A SAT-centered XAI method for Deep Learning based Video Understanding](http://arxiv.org/abs/2503.23870v2)** | 2025-05-12 |  |
| **[Gameplay Highlights Generation](http://arxiv.org/abs/2505.07721v1)** | 2025-05-12 |  |
| **[Seed1.5-VL Technical Report](http://arxiv.org/abs/2505.07062v1)** | 2025-05-11 |  |
| **[Overview of the NLPCC 2025 Shared Task 4: Multi-modal, Multilingual, and Multi-hop Medical Instructional Video Question Answering Challenge](http://arxiv.org/abs/2505.06814v1)** | 2025-05-11 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 4 tables</p></details> |
| **[DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs](http://arxiv.org/abs/2504.17040v2)** | 2025-05-10 |  |
| **[Egocentric and Exocentric Methods: A Short Survey](http://arxiv.org/abs/2410.20621v2)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted in Computer Vision and Image Understanding (CVIU), 2025</p></details> |
| **[StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](http://arxiv.org/abs/2505.05467v1)** | 2025-05-08 |  |
| **[Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](http://arxiv.org/abs/2505.02393v2)** | 2025-05-08 |  |
| **[3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark](http://arxiv.org/abs/2412.07825v3)** | 2025-05-08 | <details><summary>Proje...</summary><p>Project page: https://3dsrbench.github.io</p></details> |
| **[AffectGPT: A New Dataset, Model, and Benchmark for Emotion Understanding with Multimodal Large Language Models](http://arxiv.org/abs/2501.16566v2)** | 2025-05-07 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Efficient Adaptation For Remote Sensing Visual Grounding](http://arxiv.org/abs/2503.23083v2)** | 2025-05-13 |  |
| **[Extending Large Vision-Language Model for Diverse Interactive Tasks in Autonomous Driving](http://arxiv.org/abs/2505.08725v1)** | 2025-05-13 | <details><summary>The d...</summary><p>The dataset and code will be released at https://github.com/zc-zhao/DriveMonkey</p></details> |
| **[2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining](http://arxiv.org/abs/2501.00958v4)** | 2025-05-13 | Under review |
| **[MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification](http://arxiv.org/abs/2502.07409v2)** | 2025-05-13 |  |
| **[OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning](http://arxiv.org/abs/2505.08617v1)** | 2025-05-13 | Work in progress |
| **[From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation](http://arxiv.org/abs/2505.08548v1)** | 2025-05-13 | Early version |
| **[Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?](http://arxiv.org/abs/2505.08468v1)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted at ACL 2025 Industry Track</p></details> |
| **[DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control](http://arxiv.org/abs/2502.05855v2)** | 2025-05-13 | <details><summary>The w...</summary><p>The webpage is at https://dex-vla.github.io/</p></details> |
| **[CHOICE: Benchmarking the Remote Sensing Capabilities of Large Vision-Language Models](http://arxiv.org/abs/2411.18145v3)** | 2025-05-13 | 32 pages, 15 figures |
| **[MA-ROESL: Motion-aware Rapid Reward Optimization for Efficient Robot Skill Learning from Single Videos](http://arxiv.org/abs/2505.08367v1)** | 2025-05-13 |  |
| **[Benchmarking Multimodal Mathematical Reasoning with Explicit Visual Dependency](http://arxiv.org/abs/2504.18589v4)** | 2025-05-13 | <details><summary>Home ...</summary><p>Home page: https://alibaba-damo-academy.github.io/VCBench/</p></details> |
| **[Vision-Language Models Do Not Understand Negation](http://arxiv.org/abs/2501.09425v2)** | 2025-05-13 | <details><summary>CVPR ...</summary><p>CVPR 2025; project page: https://negbench.github.io</p></details> |
| **[Removing Watermarks with Partial Regeneration using Semantic Information](http://arxiv.org/abs/2505.08234v1)** | 2025-05-13 |  |
| **[CLTP: Contrastive Language-Tactile Pre-training for 3D Contact Geometry Understanding](http://arxiv.org/abs/2505.08194v1)** | 2025-05-13 | 16 pages |
| **[DSADF: Thinking Fast and Slow for Decision Making](http://arxiv.org/abs/2505.08189v1)** | 2025-05-13 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding](http://arxiv.org/abs/2501.01645v3)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted to ICME 2025</p></details> |
| **[MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation](http://arxiv.org/abs/2410.13757v3)** | 2025-05-13 | <details><summary>NAACL...</summary><p>NAACL 2025 Demo Track [code] https://github.com/OpenDFM/MobA [dataset] https://huggingface.co/datasets/OpenDFM/MobA-MobBench</p></details> |
| **[Visually Interpretable Subtask Reasoning for Visual Question Answering](http://arxiv.org/abs/2505.08084v1)** | 2025-05-12 |  |
| **[SCA: Improve Semantic Consistent in Unrestricted Adversarial Attacks via DDPM Inversion](http://arxiv.org/abs/2410.02240v6)** | 2025-05-12 |  |
| **[MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing](http://arxiv.org/abs/2505.07984v1)** | 2025-05-12 | <details><summary>Submi...</summary><p>Submitted to JSTARS on April 2, 2025. Code and dataset will be available upon acceptance</p></details> |
| **[Symbolic Regression with Multimodal Large Language Models and Kolmogorov Arnold Networks](http://arxiv.org/abs/2505.07956v1)** | 2025-05-12 |  |
| **[Referring to Any Person](http://arxiv.org/abs/2503.08507v2)** | 2025-05-12 |  |
| **[GeoNav: Empowering MLLMs with Explicit Geospatial Reasoning Abilities for Language-Goal Aerial Navigation](http://arxiv.org/abs/2504.09587v3)** | 2025-05-12 |  |
| **[DriveSOTIF: Advancing Perception SOTIF Through Multimodal Large Language Models](http://arxiv.org/abs/2505.07084v1)** | 2025-05-11 | <details><summary>V1 of...</summary><p>V1 of the manuscript, submitted to IEEE-TVT; V2 revision in progress</p></details> |
| **[ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use](http://arxiv.org/abs/2505.07064v1)** | 2025-05-11 |  |
| **[MELLM: Exploring LLM-Powered Micro-Expression Understanding Enhanced by Subtle Motion Perception](http://arxiv.org/abs/2505.07007v1)** | 2025-05-11 |  |
| **[Visual Evolutionary Optimization on Combinatorial Problems with Multimodal Large Language Models: A Case Study of Influence Maximization](http://arxiv.org/abs/2505.06850v1)** | 2025-05-11 |  |
| **[Visual Instruction Tuning with Chain of Region-of-Interest](http://arxiv.org/abs/2505.06840v1)** | 2025-05-11 | N/A |
| **[Batch Augmentation with Unimodal Fine-tuning for Multimodal Learning](http://arxiv.org/abs/2505.06592v1)** | 2025-05-10 |  |
| **[A Vision Centric Remote Sensing Benchmark](http://arxiv.org/abs/2503.15816v3)** | 2025-05-10 | <details><summary>Eval-...</summary><p>Eval-FoMo2 Workshop in CVPR 2025</p></details> |

