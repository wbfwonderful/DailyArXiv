---
title: Latest 15 Papers - May 22, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Just Dance with $Ï€$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection](http://arxiv.org/abs/2505.13123v1)** | 2025-05-19 |  |
| **[Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](http://arxiv.org/abs/2505.02393v2)** | 2025-05-08 |  |
| **[ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications](http://arxiv.org/abs/2505.02179v1)** | 2025-05-04 |  |
| **[Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving](http://arxiv.org/abs/2406.06423v3)** | 2025-04-28 | <details><summary>Danie...</summary><p>Daniel Bogdoll and Jan Imhof contributed equally. Accepted for publication at BMVC 2024 RROW workshop. Won Best Paper Award</p></details> |
| **[Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches](http://arxiv.org/abs/2504.14753v1)** | 2025-04-20 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Image Processing (TIP)</p></details> |
| **[EventVAD: Training-Free Event-Aware Video Anomaly Detection](http://arxiv.org/abs/2504.13092v1)** | 2025-04-17 |  |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |
| **[AssistPDA: An Online Video Surveillance Assistant for Video Anomaly Prediction, Detection, and Analysis](http://arxiv.org/abs/2503.21904v1)** | 2025-03-27 | 13 pages |
| **[VADMamba: Exploring State Space Models for Fast Video Anomaly Detection](http://arxiv.org/abs/2503.21169v1)** | 2025-03-27 | <details><summary>Accpe...</summary><p>Accpeted by ICME 2025</p></details> |
| **[Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection](http://arxiv.org/abs/2412.03044v2)** | 2025-03-27 |  |
| **[Video Anomaly Detection with Contours -- A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VideoEval-Pro: Robust and Realistic Long Video Understanding Evaluation](http://arxiv.org/abs/2505.14640v1)** | 2025-05-20 | <details><summary>Datas...</summary><p>Dataset: https://huggingface.co/datasets/TIGER-Lab/VideoEval-Pro, Project Webpage: https://tiger-ai-lab.github.io/VideoEval-Pro</p></details> |
| **[Video Compression Commander: Plug-and-Play Inference Acceleration for Video Large Language Models](http://arxiv.org/abs/2505.14454v1)** | 2025-05-20 | <details><summary>Our c...</summary><p>Our code is available at https://github.com/xuyang-liu16/VidCom2</p></details> |
| **[Breaking Down Video LLM Benchmarks: Knowledge, Spatial Perception, or True Temporal Understanding?](http://arxiv.org/abs/2505.14321v1)** | 2025-05-20 |  |
| **[InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model](http://arxiv.org/abs/2501.12368v2)** | 2025-05-20 | ACL 2025 Findings |
| **[Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation](http://arxiv.org/abs/2504.02438v4)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |
| **[LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts](http://arxiv.org/abs/2505.13928v1)** | 2025-05-20 |  |
| **[MomentSeeker: A Task-Oriented Benchmark For Long-Video Moment Retrieval](http://arxiv.org/abs/2502.12558v4)** | 2025-05-20 |  |
| **[Domain Adaptation of VLM for Soccer Video Understanding](http://arxiv.org/abs/2505.13860v1)** | 2025-05-20 | <details><summary>8 pag...</summary><p>8 pages, 5 figures, accepted to the 11th IEEE International Workshop on Computer Vision in Sports (CVSports) at CVPR 2025; supplementary appendix included as ancillary PDF</p></details> |
| **[A Challenge to Build Neuro-Symbolic Video Agents](http://arxiv.org/abs/2505.13851v1)** | 2025-05-20 |  |
| **[FIOVA: A Multi-Annotator Benchmark for Human-Aligned Video Captioning](http://arxiv.org/abs/2410.15270v2)** | 2025-05-19 |  |
| **[$\infty$-Video: A Training-Free Approach to Long Video Understanding via Continuous-Time Memory Consolidation](http://arxiv.org/abs/2501.19098v2)** | 2025-05-19 | 17 pages, 7 figures |
| **[Temporal-Oriented Recipe for Transferring Large Vision-Language Model to Video Understanding](http://arxiv.org/abs/2505.12605v1)** | 2025-05-19 | In Progress |
| **[From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations](http://arxiv.org/abs/2505.12237v1)** | 2025-05-18 |  |
| **[Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding](http://arxiv.org/abs/2503.13139v2)** | 2025-05-17 | <details><summary>32 pa...</summary><p>32 pages, under review</p></details> |
| **[VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding](http://arxiv.org/abs/2505.01481v2)** | 2025-05-16 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens](http://arxiv.org/abs/2505.14671v1)** | 2025-05-20 |  |
| **[CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation](http://arxiv.org/abs/2505.14646v1)** | 2025-05-20 |  |
| **[Debating for Better Reasoning: An Unsupervised Multimodal Approach](http://arxiv.org/abs/2505.14627v1)** | 2025-05-20 |  |
| **[PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models](http://arxiv.org/abs/2505.14481v1)** | 2025-05-20 |  |
| **[RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding](http://arxiv.org/abs/2505.14462v1)** | 2025-05-20 |  |
| **[Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model](http://arxiv.org/abs/2503.16282v2)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[Does Acceleration Cause Hidden Instability in Vision Language Models? Uncovering Instance-Level Divergence Through a Large-Scale Empirical Study](http://arxiv.org/abs/2503.06794v3)** | 2025-05-20 |  |
| **[SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation](http://arxiv.org/abs/2505.14381v1)** | 2025-05-20 | v1 |
| **[Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization](http://arxiv.org/abs/2502.01051v3)** | 2025-05-20 | <details><summary>25 pa...</summary><p>25 pages, 26 tables, 15 figures</p></details> |
| **[Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds](http://arxiv.org/abs/2505.14366v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to: Intelligent Autonomous Systems (IAS) 2025 as Late Breaking Report</p></details> |
| **[DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning](http://arxiv.org/abs/2505.14362v1)** | 2025-05-20 |  |
| **[Vision-Language Modeling Meets Remote Sensing: Models, Datasets and Perspectives](http://arxiv.org/abs/2505.14361v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted by IEEE Geoscience and Remote Sensing Magazine</p></details> |
| **[Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey](http://arxiv.org/abs/2505.14340v1)** | 2025-05-20 | 18 pages |
| **[Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education](http://arxiv.org/abs/2502.05863v2)** | 2025-05-20 |  |
| **[Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models](http://arxiv.org/abs/2505.14257v1)** | 2025-05-20 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation](http://arxiv.org/abs/2505.14682v1)** | 2025-05-20 | Technical report |
| **[MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models](http://arxiv.org/abs/2502.11051v3)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted as ACL 2025 Findings</p></details> |
| **[ModRWKV: Transformer Multimodality in Linear Time](http://arxiv.org/abs/2505.14505v1)** | 2025-05-20 |  |
| **[A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges](http://arxiv.org/abs/2412.11936v3)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted by The 63rd Annual Meeting of the Association for Computational Linguistics (ACL Findings 2025)</p></details> |
| **[Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents](http://arxiv.org/abs/2505.14418v1)** | 2025-05-20 | <details><summary>25 pa...</summary><p>25 pages, 10 figures, 12 Tables</p></details> |
| **[MathAgent: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection](http://arxiv.org/abs/2503.18132v2)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted by The 63rd Annual Meeting of the Association for Computational Linguistics (ACL Industry 2025, Oral Presentation)</p></details> |
| **[Speculative Decoding Reimagined for Multimodal Large Language Models](http://arxiv.org/abs/2505.14260v1)** | 2025-05-20 | 12 pages |
| **[UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning](http://arxiv.org/abs/2505.14231v1)** | 2025-05-20 |  |
| **[MCiteBench: A Multimodal Benchmark for Generating Text with Citations](http://arxiv.org/abs/2503.02589v3)** | 2025-05-20 | <details><summary>https...</summary><p>https://caiyuhu.github.io/MCiteBench/</p></details> |
| **[EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models](http://arxiv.org/abs/2502.11916v2)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted by ACL Findings 2025</p></details> |
| **[Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models](http://arxiv.org/abs/2505.14071v1)** | 2025-05-20 |  |
| **[Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models](http://arxiv.org/abs/2505.13973v1)** | 2025-05-20 |  |
| **[CAFES: A Collaborative Multi-Agent Framework for Multi-Granular Multimodal Essay Scoring](http://arxiv.org/abs/2505.13965v1)** | 2025-05-20 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2502.11916</p></details> |
| **[Visual Instruction Bottleneck Tuning](http://arxiv.org/abs/2505.13946v1)** | 2025-05-20 |  |
| **[Open3DVQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space](http://arxiv.org/abs/2503.11094v2)** | 2025-05-20 |  |

