---
title: Latest 15 Papers - September 10, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](http://arxiv.org/abs/2506.18368v3)** | 2025-09-03 | ICCV 2025 Highlight |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Harnessing Object Grounding for Time-Sensitive Video Understanding](http://arxiv.org/abs/2509.06335v1)** | 2025-09-08 |  |
| **[Kwai Keye-VL 1.5 Technical Report](http://arxiv.org/abs/2509.01563v3)** | 2025-09-07 | <details><summary>Githu...</summary><p>Github page: https://github.com/Kwai-Keye/Keye</p></details> |
| **[VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding](http://arxiv.org/abs/2508.06869v2)** | 2025-09-06 | 9 pages,3 figures |
| **[Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data](http://arxiv.org/abs/2509.03501v1)** | 2025-09-03 | <details><summary>This ...</summary><p>This technical report serves as the archival version of our paper accepted at the ICCV 2025 Workshop. For more information, please visit our project website: https://strefer.github.io/</p></details> |
| **[Time-Scaling State-Space Models for Dense Video Captioning](http://arxiv.org/abs/2509.03426v1)** | 2025-09-03 | BMVC 2025 |
| **[Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning](http://arxiv.org/abs/2508.04416v2)** | 2025-09-03 |  |
| **[Exploring Response Uncertainty in MLLMs: An Empirical Evaluation under Misleading Scenarios](http://arxiv.org/abs/2411.02708v3)** | 2025-09-03 |  |
| **[ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](http://arxiv.org/abs/2508.21496v2)** | 2025-09-02 |  |
| **[Generative Frame Sampler for Long Video Understanding](http://arxiv.org/abs/2503.09146v2)** | 2025-09-02 | <details><summary>ACL 2...</summary><p>ACL 2025 Findings. Code: https://github.com/yaolinli/GenS</p></details> |
| **[Variation-aware Vision Token Dropping for Faster Large Vision-Language Models](http://arxiv.org/abs/2509.01552v1)** | 2025-09-01 | <details><summary>Code:...</summary><p>Code: \url{https://github.com/xuyang-liu16/V2Drop}</p></details> |
| **[MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning](http://arxiv.org/abs/2508.04549v3)** | 2025-09-01 | <details><summary>Publi...</summary><p>Published at ACMMM2025 (Dataset track)</p></details> |
| **[Temporal Preference Optimization for Long-Form Video Understanding](http://arxiv.org/abs/2501.13919v3)** | 2025-09-01 |  |
| **[Do Video Language Models Really Know Where to Look? Diagnosing Attention Failures in Video Language Models](http://arxiv.org/abs/2509.01167v1)** | 2025-09-01 | preprint |
| **[LvBench: A Benchmark for Long-form Video Understanding with Versatile Multi-modal Question Answering](http://arxiv.org/abs/2312.04817v2)** | 2025-09-01 |  |
| **[Seeing More, Saying More: Lightweight Language Experts are Dynamic Video Token Compressors](http://arxiv.org/abs/2509.00969v1)** | 2025-08-31 | <details><summary>17pag...</summary><p>17pages, 8 figures, EMNLP2025</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLaDA-VLA: Vision Language Diffusion Action Models](http://arxiv.org/abs/2509.06932v1)** | 2025-09-08 |  |
| **[D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning](http://arxiv.org/abs/2509.06771v1)** | 2025-09-08 | <details><summary>Accep...</summary><p>Accepted at IEEE International Conference on Data Mining (ICDM) 2025</p></details> |
| **[Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots](http://arxiv.org/abs/2509.06768v1)** | 2025-09-08 |  |
| **[Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization](http://arxiv.org/abs/2509.06759v1)** | 2025-09-08 | <details><summary>Accep...</summary><p>Accepted for publication in the Proceedings of the 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025)</p></details> |
| **[Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs](http://arxiv.org/abs/2506.22146v3)** | 2025-09-08 |  |
| **[Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning](http://arxiv.org/abs/2509.06461v1)** | 2025-09-08 |  |
| **[E-THER: A Multimodal Dataset for Empathic AI -- Towards Emotional Mismatch Awareness](http://arxiv.org/abs/2509.02100v2)** | 2025-09-08 | <details><summary>15 pa...</summary><p>15 pages, 4 figures. Preprint</p></details> |
| **[When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection](http://arxiv.org/abs/2509.06427v1)** | 2025-09-08 |  |
| **[Content Generation Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges](http://arxiv.org/abs/2505.10993v2)** | 2025-09-08 | 20 pages, 8 figures |
| **[Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models](http://arxiv.org/abs/2509.06415v1)** | 2025-09-08 | <details><summary>Submi...</summary><p>Submitted to ICASSP 2026</p></details> |
| **[Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning](http://arxiv.org/abs/2509.06409v1)** | 2025-09-08 |  |
| **[REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](http://arxiv.org/abs/2508.12543v2)** | 2025-09-08 | <details><summary>4 pag...</summary><p>4 pages, 6 figures, International Conference on Computer Vision, ICCV 2025</p></details> |
| **[VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making](http://arxiv.org/abs/2503.15108v2)** | 2025-09-08 |  |
| **[Multi View Slot Attention Using Paraphrased Texts For Face Anti-Spoofing](http://arxiv.org/abs/2509.06336v1)** | 2025-09-08 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models](http://arxiv.org/abs/2509.01350v2)** | 2025-09-08 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation](http://arxiv.org/abs/2509.05263v2)** | 2025-09-08 |  |
| **[Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization](http://arxiv.org/abs/2509.06759v1)** | 2025-09-08 | <details><summary>Accep...</summary><p>Accepted for publication in the Proceedings of the 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025)</p></details> |
| **[MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs](http://arxiv.org/abs/2503.13111v2)** | 2025-09-08 | ICCV 2025 |
| **[Text4Seg++: Advancing Image Segmentation via Generative Language Modeling](http://arxiv.org/abs/2509.06321v1)** | 2025-09-08 | <details><summary>Exten...</summary><p>Extended version of our conference paper arXiv:2410.09855</p></details> |
| **[Enhancing Low-Altitude Airspace Security: MLLM-Enabled UAV Intent Recognition](http://arxiv.org/abs/2509.06312v1)** | 2025-09-08 | <details><summary>The p...</summary><p>The paper has been submitted to IEEE Internet of Things Magazine</p></details> |
| **[Kwai Keye-VL 1.5 Technical Report](http://arxiv.org/abs/2509.01563v3)** | 2025-09-07 | <details><summary>Githu...</summary><p>Github page: https://github.com/Kwai-Keye/Keye</p></details> |
| **[BTCChat: Advancing Remote Sensing Bi-temporal Change Captioning with Multimodal Large Language Model](http://arxiv.org/abs/2509.05895v1)** | 2025-09-07 | <details><summary>5 pag...</summary><p>5 pages, 2 figures Submitted to ICASSP 2026</p></details> |
| **[Towards Synthesizing Normative Data for Cognitive Assessments Using Generative Multimodal Large Language Models](http://arxiv.org/abs/2508.17675v3)** | 2025-09-06 | Preprint |
| **[Parameter-Efficient Adaptation of mPLUG-Owl2 via Pixel-Level Visual Prompts for NR-IQA](http://arxiv.org/abs/2509.03494v2)** | 2025-09-06 |  |
| **[VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding](http://arxiv.org/abs/2508.06869v2)** | 2025-09-06 | 9 pages,3 figures |
| **[Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs](http://arxiv.org/abs/2509.05714v1)** | 2025-09-06 | 15 pages, 6 figures |
| **[Osprey: Pixel Understanding with Visual Instruction Tuning](http://arxiv.org/abs/2312.10032v4)** | 2025-09-06 | <details><summary>CVPR2...</summary><p>CVPR2024, Code and Demo link:https://github.com/CircleRadon/Osprey</p></details> |
| **[OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision](http://arxiv.org/abs/2509.05578v1)** | 2025-09-06 |  |
| **[FairReason: Balancing Reasoning and Social Bias in MLLMs](http://arxiv.org/abs/2507.23067v2)** | 2025-09-06 | <details><summary>Accep...</summary><p>Accepted to the Trustworthy FMs workshop in ICCV 2025</p></details> |
| **[Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety](http://arxiv.org/abs/2508.03864v2)** | 2025-09-06 | <details><summary>accep...</summary><p>accepted by the Trustworthy FMs workshop in ICCV 2025</p></details> |

