---
title: Latest 15 Papers - May 20, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](http://arxiv.org/abs/2505.02393v2)** | 2025-05-08 |  |
| **[ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications](http://arxiv.org/abs/2505.02179v1)** | 2025-05-04 |  |
| **[Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving](http://arxiv.org/abs/2406.06423v3)** | 2025-04-28 | <details><summary>Danie...</summary><p>Daniel Bogdoll and Jan Imhof contributed equally. Accepted for publication at BMVC 2024 RROW workshop. Won Best Paper Award</p></details> |
| **[Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches](http://arxiv.org/abs/2504.14753v1)** | 2025-04-20 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Image Processing (TIP)</p></details> |
| **[EventVAD: Training-Free Event-Aware Video Anomaly Detection](http://arxiv.org/abs/2504.13092v1)** | 2025-04-17 |  |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |
| **[AssistPDA: An Online Video Surveillance Assistant for Video Anomaly Prediction, Detection, and Analysis](http://arxiv.org/abs/2503.21904v1)** | 2025-03-27 | 13 pages |
| **[VADMamba: Exploring State Space Models for Fast Video Anomaly Detection](http://arxiv.org/abs/2503.21169v1)** | 2025-03-27 | <details><summary>Accpe...</summary><p>Accpeted by ICME 2025</p></details> |
| **[Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection](http://arxiv.org/abs/2412.03044v2)** | 2025-03-27 |  |
| **[Video Anomaly Detection with Contours -- A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding](http://arxiv.org/abs/2505.01481v2)** | 2025-05-16 |  |
| **[Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model](http://arxiv.org/abs/2412.04729v3)** | 2025-05-16 | 16 pages |
| **[Empowering Agentic Video Analytics Systems with Video Language Models](http://arxiv.org/abs/2505.00254v3)** | 2025-05-16 | <details><summary>15 pa...</summary><p>15 pages, AVAS, add latency breakdown</p></details> |
| **[SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation](http://arxiv.org/abs/2505.08665v1)** | 2025-05-13 |  |
| **[VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large Video Language Models](http://arxiv.org/abs/2505.08455v1)** | 2025-05-13 |  |
| **[SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding](http://arxiv.org/abs/2504.21435v3)** | 2025-05-13 | <details><summary>29 pa...</summary><p>29 pages, 15 figures, CVPR 2025</p></details> |
| **[HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding](http://arxiv.org/abs/2501.01645v3)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted to ICME 2025</p></details> |
| **[An Analysis of Data Transformation Effects on Segment Anything 2](http://arxiv.org/abs/2503.00042v2)** | 2025-05-13 | 11 pages, 30 figures |
| **[A SAT-centered XAI method for Deep Learning based Video Understanding](http://arxiv.org/abs/2503.23870v2)** | 2025-05-12 |  |
| **[Gameplay Highlights Generation](http://arxiv.org/abs/2505.07721v1)** | 2025-05-12 |  |
| **[Seed1.5-VL Technical Report](http://arxiv.org/abs/2505.07062v1)** | 2025-05-11 |  |
| **[Overview of the NLPCC 2025 Shared Task 4: Multi-modal, Multilingual, and Multi-hop Medical Instructional Video Question Answering Challenge](http://arxiv.org/abs/2505.06814v1)** | 2025-05-11 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 4 tables</p></details> |
| **[DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs](http://arxiv.org/abs/2504.17040v2)** | 2025-05-10 |  |
| **[Egocentric and Exocentric Methods: A Short Survey](http://arxiv.org/abs/2410.20621v2)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted in Computer Vision and Image Understanding (CVIU), 2025</p></details> |
| **[StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](http://arxiv.org/abs/2505.05467v1)** | 2025-05-08 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language Models on Context-Aware Hazard Detection and Edge Case Evaluation](http://arxiv.org/abs/2502.00262v3)** | 2025-05-16 |  |
| **[Disentangling CLIP for Multi-Object Perception](http://arxiv.org/abs/2502.02977v3)** | 2025-05-16 |  |
| **[Evaluating Vision-Language Models as Evaluators in Path Planning](http://arxiv.org/abs/2411.18711v4)** | 2025-05-16 | <details><summary>Accep...</summary><p>Accepted to the 2025 IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR)</p></details> |
| **[Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner](http://arxiv.org/abs/2505.11404v1)** | 2025-05-16 |  |
| **[Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild](http://arxiv.org/abs/2505.11350v1)** | 2025-05-16 |  |
| **[Flex: End-to-End Text-Instructed Visual Navigation from Foundation Model Features](http://arxiv.org/abs/2410.13002v2)** | 2025-05-16 |  |
| **[Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models](http://arxiv.org/abs/2505.11326v1)** | 2025-05-16 | 18 pages |
| **[Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model](http://arxiv.org/abs/2412.04729v3)** | 2025-05-16 | 16 pages |
| **[Sample Efficient Reinforcement Learning via Large Vision Language Model Distillation](http://arxiv.org/abs/2505.11221v1)** | 2025-05-16 | <details><summary>5 pag...</summary><p>5 pages, ICASSP 2025. The first two authors are equally contributed</p></details> |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v4)** | 2025-05-16 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing](http://arxiv.org/abs/2505.11121v1)** | 2025-05-16 | <details><summary>Accep...</summary><p>Accepted at IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2025. Our code is available at https://git.tu-berlin.de/rsim/redundacy-aware-rs-vlm</p></details> |
| **[Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Pathology Analysis](http://arxiv.org/abs/2412.09521v3)** | 2025-05-16 |  |
| **[CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs](http://arxiv.org/abs/2505.11060v1)** | 2025-05-16 | <details><summary>8 pag...</summary><p>8 pages, 3 figures, 5 tables. Accepted at IJCNN 2025; to appear in IEEE Xplore</p></details> |
| **[Exploiting the Asymmetric Uncertainty Structure of Pre-trained VLMs on the Unit Hypersphere](http://arxiv.org/abs/2505.11029v1)** | 2025-05-16 |  |
| **[AVA: Attentive VLM Agent for Mastering StarCraft II](http://arxiv.org/abs/2503.05383v5)** | 2025-05-16 | Under Review |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art](http://arxiv.org/abs/2505.11436v1)** | 2025-05-16 | <details><summary>69 pa...</summary><p>69 pages, 66 figures, accepted by ACL 2025</p></details> |
| **[EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models](http://arxiv.org/abs/2505.11405v1)** | 2025-05-16 |  |
| **[TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs](http://arxiv.org/abs/2505.11275v1)** | 2025-05-16 | Preprint |
| **[Augmented Object Intelligence with XR-Objects](http://arxiv.org/abs/2404.13274v5)** | 2025-05-16 | <details><summary>15 pa...</summary><p>15 pages, 15 figures, 2024 ACM Symposium on User Interface Software and Technology (UIST)</p></details> |
| **[V-MAGE: A Game Evaluation Framework for Assessing Vision-Centric Capabilities in Multimodal Large Language Models](http://arxiv.org/abs/2504.06148v2)** | 2025-05-16 |  |
| **[Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans](http://arxiv.org/abs/2505.11141v1)** | 2025-05-16 |  |
| **[WildDoc: How Far Are We from Achieving Comprehensive and Robust Document Understanding in the Wild?](http://arxiv.org/abs/2505.11015v1)** | 2025-05-16 |  |
| **[ToDMA: Large Model-Driven Token-Domain Multiple Access for Semantic Communications](http://arxiv.org/abs/2505.10946v1)** | 2025-05-16 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2502.06118</p></details> |
| **[From Image to Video, what do we need in multimodal LLMs?](http://arxiv.org/abs/2404.11865v2)** | 2025-05-16 |  |
| **[VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization](http://arxiv.org/abs/2505.10917v1)** | 2025-05-16 |  |
| **[Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?](http://arxiv.org/abs/2505.10862v1)** | 2025-05-16 | <details><summary>6 pag...</summary><p>6 pages, 5 figures, 2 tables</p></details> |
| **[Unifying Segment Anything in Microscopy with Multimodal Large Language Model](http://arxiv.org/abs/2505.10769v1)** | 2025-05-16 | 18 pages, 9 figures |
| **[Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis](http://arxiv.org/abs/2505.10541v1)** | 2025-05-15 |  |
| **[Unified Modeling Language Code Generation from Diagram Images Using Multimodal Large Language Models](http://arxiv.org/abs/2503.12293v2)** | 2025-05-15 | <details><summary>Publi...</summary><p>Published in the Journal of Machine Learning with Applications, Author Contributions: Averi Bates: Methodology, Development, Analysis, Data Curation, Drafting, Review. Ryan Vavricka: Data Curation, Development, Review. Shane Carleton: Supervision, Funding. Ruosi Shao: Review. Chongle Pan: Supervision, Review</p></details> |
| **[Scaling Laws for Black box Adversarial Attacks](http://arxiv.org/abs/2411.16782v2)** | 2025-05-15 |  |

