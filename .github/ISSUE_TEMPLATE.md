---
title: Latest 15 Papers - April 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |
| **[AssistPDA: An Online Video Surveillance Assistant for Video Anomaly Prediction, Detection, and Analysis](http://arxiv.org/abs/2503.21904v1)** | 2025-03-27 | 13 pages |
| **[VADMamba: Exploring State Space Models for Fast Video Anomaly Detection](http://arxiv.org/abs/2503.21169v1)** | 2025-03-27 | <details><summary>Accpe...</summary><p>Accpeted by ICME 2025</p></details> |
| **[Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection](http://arxiv.org/abs/2412.03044v2)** | 2025-03-27 |  |
| **[Video Anomaly Detection with Contours -- A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |
| **[Anomize: Better Open Vocabulary Video Anomaly Detection](http://arxiv.org/abs/2503.18094v1)** | 2025-03-23 |  |
| **[Towards Adaptive Human-centric Video Anomaly Detection: A Comprehensive Framework and A New Benchmark](http://arxiv.org/abs/2408.14329v2)** | 2025-03-19 |  |
| **[Human-Centric Video Anomaly Detection Through Spatio-Temporal Pose Tokenization and Transformer](http://arxiv.org/abs/2408.15185v2)** | 2025-03-17 |  |
| **[Language-guided Open-world Video Anomaly Detection](http://arxiv.org/abs/2503.13160v1)** | 2025-03-17 |  |
| **[UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks](http://arxiv.org/abs/2503.12905v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted by AAAI 2025</p></details> |
| **[Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos](http://arxiv.org/abs/2503.07799v1)** | 2025-03-10 |  |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Towards Efficient and Robust Moment Retrieval System: A Unified Framework for Multi-Granularity Models and Temporal Reranking](http://arxiv.org/abs/2504.08384v1)** | 2025-04-11 |  |
| **[SpaceVLLM: Endowing Multimodal Large Language Model with Spatio-Temporal Video Grounding Capability](http://arxiv.org/abs/2503.13983v3)** | 2025-04-11 |  |
| **[F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos](http://arxiv.org/abs/2504.08222v1)** | 2025-04-11 | <details><summary>The T...</summary><p>The Thirteenth International Conference on Learning Representations (ICLR 2025)</p></details> |
| **[VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning](http://arxiv.org/abs/2504.06958v2)** | 2025-04-10 |  |
| **[SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding](http://arxiv.org/abs/2504.07745v1)** | 2025-04-10 | Accepted to CVPR2025 |
| **[VideoExpert: Augmented LLM for Temporal-Sensitive Video Understanding](http://arxiv.org/abs/2504.07519v1)** | 2025-04-10 |  |
| **[How Can Objects Help Video-Language Understanding?](http://arxiv.org/abs/2504.07454v1)** | 2025-04-10 |  |
| **[LVC: A Lightweight Compression Framework for Enhancing VLMs in Long Video Understanding](http://arxiv.org/abs/2504.06835v1)** | 2025-04-09 |  |
| **[AuroraCap: Efficient, Performant Video Detailed Captioning and a New Benchmark](http://arxiv.org/abs/2410.03051v4)** | 2025-04-09 | <details><summary>Accep...</summary><p>Accepted to ICLR 2025. Code, docs, weight, benchmark and training data are all avaliable at https://rese1f.github.io/aurora-web/</p></details> |
| **[From Broadcast to Minimap: Achieving State-of-the-Art SoccerNet Game State Reconstruction](http://arxiv.org/abs/2504.06357v1)** | 2025-04-08 | <details><summary>Accep...</summary><p>Accepted for presentation at the CVPR 2025 CVsports Workshop</p></details> |
| **[From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models](http://arxiv.org/abs/2504.06214v1)** | 2025-04-08 |  |
| **[Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation](http://arxiv.org/abs/2504.02438v2)** | 2025-04-08 |  |
| **[REEF: Relevance-Aware and Efficient LLM Adapter for Video Understanding](http://arxiv.org/abs/2504.05491v1)** | 2025-04-07 | Accepted at CVPRW'25 |
| **[InstructionBench: An Instructional Video Understanding Benchmark](http://arxiv.org/abs/2504.05040v1)** | 2025-04-07 |  |
| **[Is Temporal Prompting All We Need For Limited Labeled Action Recognition?](http://arxiv.org/abs/2504.01890v2)** | 2025-04-07 | <details><summary>Accep...</summary><p>Accepted in CVPR-W 2025</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning](http://arxiv.org/abs/2412.16739v2)** | 2025-04-11 | Accepted by CVPR2025 |
| **[AstroLLaVA: towards the unification of astronomical data and natural language](http://arxiv.org/abs/2504.08583v1)** | 2025-04-11 | <details><summary>8 pag...</summary><p>8 pages, 3 figures, accepted to SCI-FM@ICLR 2025. Code at https://w3id.org/UniverseTBD/AstroLLaVA</p></details> |
| **[DSBench: How Far Are Data Science Agents from Becoming Data Science Experts?](http://arxiv.org/abs/2409.07703v3)** | 2025-04-11 |  |
| **[Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection](http://arxiv.org/abs/2409.02664v4)** | 2025-04-11 | <details><summary>Accep...</summary><p>Accepted by AAAI 2025</p></details> |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v2)** | 2025-04-11 | <details><summary>Submi...</summary><p>Submitted to CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[CLAP: Isolating Content from Style through Contrastive Learning with Augmented Prompts](http://arxiv.org/abs/2311.16445v5)** | 2025-04-11 | <details><summary>Accep...</summary><p>Accepted as a conference paper at ECCV 2024</p></details> |
| **[IFShip: Interpretable Fine-grained Ship Classification with Domain Knowledge-Enhanced Vision-Language Models](http://arxiv.org/abs/2408.06631v3)** | 2025-04-11 |  |
| **[EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models](http://arxiv.org/abs/2504.08205v1)** | 2025-04-11 | <details><summary>Prese...</summary><p>Presented as a poster at ACSAC 2024</p></details> |
| **[Investigating Vision-Language Model for Point Cloud-based Vehicle Classification](http://arxiv.org/abs/2504.08154v1)** | 2025-04-10 | <details><summary>5 pag...</summary><p>5 pages,3 figures, 1 table, CVPR DriveX workshop</p></details> |
| **[The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search](http://arxiv.org/abs/2504.08066v1)** | 2025-04-10 |  |
| **[VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning](http://arxiv.org/abs/2504.07956v1)** | 2025-04-10 |  |
| **[SAMJAM: Zero-Shot Video Scene Graph Generation for Egocentric Kitchen Videos](http://arxiv.org/abs/2504.07867v1)** | 2025-04-10 |  |
| **[ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering](http://arxiv.org/abs/2504.05506v2)** | 2025-04-10 |  |
| **[LATTE: Lightweight Attention-based Traffic Accident Anticipation Engine](http://arxiv.org/abs/2504.04103v2)** | 2025-04-10 | <details><summary>Accep...</summary><p>Accept by Information Fusion (Elsevier)</p></details> |
| **[CollEX -- A Multimodal Agentic RAG System Enabling Interactive Exploration of Scientific Collections](http://arxiv.org/abs/2504.07643v1)** | 2025-04-10 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Fine-Grained Retrieval-Augmented Generation for Visual Question Answering](http://arxiv.org/abs/2502.20964v2)** | 2025-04-11 |  |
| **[MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning](http://arxiv.org/abs/2401.10727v3)** | 2025-04-11 | WACV 2025 |
| **[DSM: Building A Diverse Semantic Map for 3D Visual Grounding](http://arxiv.org/abs/2504.08307v1)** | 2025-04-11 | <details><summary>8 pag...</summary><p>8 pages, 6 figures, submitted to IROS, Project Page: https://binicey.github.io/DSM</p></details> |
| **[EgoPlan-Bench2: A Benchmark for Multimodal Large Language Model Planning in Real-World Scenarios](http://arxiv.org/abs/2412.04447v2)** | 2025-04-11 | <details><summary>Code ...</summary><p>Code & data are available at: https://qiulu66.github.io/egoplanbench2/</p></details> |
| **[SpaceVLLM: Endowing Multimodal Large Language Model with Spatio-Temporal Video Grounding Capability](http://arxiv.org/abs/2503.13983v3)** | 2025-04-11 |  |
| **[EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents](http://arxiv.org/abs/2501.11858v2)** | 2025-04-11 |  |
| **[POEM: Precise Object-level Editing via MLLM control](http://arxiv.org/abs/2504.08111v1)** | 2025-04-10 | <details><summary>Accep...</summary><p>Accepted to SCIA 2025</p></details> |
| **[Liquid: Language Models are Scalable and Unified Multi-modal Generators](http://arxiv.org/abs/2412.04332v4)** | 2025-04-10 | <details><summary>Techn...</summary><p>Technical report. Project page: https://foundationvision.github.io/Liquid/</p></details> |
| **[VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning](http://arxiv.org/abs/2504.06958v2)** | 2025-04-10 |  |
| **[Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal Large Language Models](http://arxiv.org/abs/2504.07521v1)** | 2025-04-10 | <details><summary>Accep...</summary><p>Accepted at CVPR Workshop NEXD 2025. 21 pages, Project: https://github.com/Lum1104/EIBench</p></details> |
| **[VideoExpert: Augmented LLM for Temporal-Sensitive Video Understanding](http://arxiv.org/abs/2504.07519v1)** | 2025-04-10 |  |
| **[How Can Objects Help Video-Language Understanding?](http://arxiv.org/abs/2504.07454v1)** | 2025-04-10 |  |
| **[Routing to the Right Expertise: A Trustworthy Judge for Instruction-based Image Editing](http://arxiv.org/abs/2504.07424v1)** | 2025-04-10 |  |
| **[Law of Vision Representation in MLLMs](http://arxiv.org/abs/2408.16357v2)** | 2025-04-09 | <details><summary>The c...</summary><p>The code is available at https://github.com/bronyayang/Law_of_Vision_Representation_in_MLLMs</p></details> |
| **[Face-LLaVA: Facial Expression and Attribute Understanding through Instruction Tuning](http://arxiv.org/abs/2504.07198v1)** | 2025-04-09 | <details><summary>Proje...</summary><p>Project Page: https://face-llava.github.io</p></details> |

