---
title: Latest 15 Papers - March 27, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Video Anomaly Detection with Contours - A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |
| **[Anomize: Better Open Vocabulary Video Anomaly Detection](http://arxiv.org/abs/2503.18094v1)** | 2025-03-23 |  |
| **[Towards Adaptive Human-centric Video Anomaly Detection: A Comprehensive Framework and A New Benchmark](http://arxiv.org/abs/2408.14329v2)** | 2025-03-19 |  |
| **[Human-Centric Video Anomaly Detection Through Spatio-Temporal Pose Tokenization and Transformer](http://arxiv.org/abs/2408.15185v2)** | 2025-03-17 |  |
| **[Language-guided Open-world Video Anomaly Detection](http://arxiv.org/abs/2503.13160v1)** | 2025-03-17 |  |
| **[UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks](http://arxiv.org/abs/2503.12905v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted by AAAI 2025</p></details> |
| **[Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos](http://arxiv.org/abs/2503.07799v1)** | 2025-03-10 |  |
| **[Dual Conditioned Motion Diffusion for Pose-Based Video Anomaly Detection](http://arxiv.org/abs/2412.17210v2)** | 2025-03-08 | <details><summary>Code ...</summary><p>Code is on https://github.com/guijiejie/DCMD-main</p></details> |
| **[Video Anomaly Detection with Structured Keywords](http://arxiv.org/abs/2503.10653v1)** | 2025-03-07 |  |
| **[AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM](http://arxiv.org/abs/2503.04504v1)** | 2025-03-06 |  |
| **[Anomaly detection in non-stationary videos using time-recursive differencing network based prediction](http://arxiv.org/abs/2503.02234v1)** | 2025-03-04 | <details><summary>Copyr...</summary><p>Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Transformer Based Self-Context Aware Prediction for Few-Shot Anomaly Detection in Videos](http://arxiv.org/abs/2503.00670v1)** | 2025-03-02 | <details><summary>Copyr...</summary><p>Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion](http://arxiv.org/abs/2410.01506v4)** | 2025-02-28 | <details><summary>Accep...</summary><p>Accepted at the Thirteenth International Conference on Learning Representations (ICLR 2025)</p></details> |
| **[Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive LLM](http://arxiv.org/abs/2502.18863v1)** | 2025-02-26 |  |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From My View to Yours: Ego-Augmented Learning in Large Vision Language Models for Understanding Exocentric Daily Living Activities](http://arxiv.org/abs/2501.05711v2)** | 2025-03-25 |  |
| **[PAVE: Patching and Adapting Video Large Language Models](http://arxiv.org/abs/2503.19794v1)** | 2025-03-25 | <details><summary>CVPR2...</summary><p>CVPR2025 Camera Ready</p></details> |
| **[Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations](http://arxiv.org/abs/2503.19706v1)** | 2025-03-25 | <details><summary>CVPR ...</summary><p>CVPR 2025 Camera-ready</p></details> |
| **[Exploring Hallucination of Large Multimodal Models in Video Understanding: Benchmark, Analysis and Mitigation](http://arxiv.org/abs/2503.19622v1)** | 2025-03-25 |  |
| **[DynFocus: Dynamic Cooperative Network Empowers LLMs with Video Understanding](http://arxiv.org/abs/2411.12355v2)** | 2025-03-25 | Accepted by CVPR 25 |
| **[Lost in Time: A New Temporal Benchmark for VideoLLMs](http://arxiv.org/abs/2410.07752v3)** | 2025-03-25 |  |
| **[VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM](http://arxiv.org/abs/2501.00599v3)** | 2025-03-25 | <details><summary>17 pa...</summary><p>17 pages, 14 figures, technical report</p></details> |
| **[STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding](http://arxiv.org/abs/2503.15973v2)** | 2025-03-25 |  |
| **[Zero-shot Action Localization via the Confidence of Large Vision-Language Models](http://arxiv.org/abs/2410.14340v2)** | 2025-03-24 |  |
| **[SlowFast-LLaVA-1.5: A Family of Token-Efficient Video Large Language Models for Long-Form Video Understanding](http://arxiv.org/abs/2503.18943v1)** | 2025-03-24 | Technical report |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |
| **[Beyond Training: Dynamic Token Merging for Zero-Shot Video Understanding](http://arxiv.org/abs/2411.14401v2)** | 2025-03-24 | <details><summary>Code ...</summary><p>Code is available at https://github.com/Jam1ezhang/DYTO</p></details> |
| **[Multiple Object Tracking as ID Prediction](http://arxiv.org/abs/2403.16848v2)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025</p></details> |
| **[Towards Universal Soccer Video Understanding](http://arxiv.org/abs/2412.01820v3)** | 2025-03-24 | <details><summary>CVPR ...</summary><p>CVPR 2025; Project Page: https://jyrao.github.io/UniSoccer/</p></details> |
| **[Unbiasing through Textual Descriptions: Mitigating Representation Bias in Video Benchmarks](http://arxiv.org/abs/2503.18637v1)** | 2025-03-24 | <details><summary>To be...</summary><p>To be published at CVPR 2025, project webpage https://utd-project.github.io/</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CoLLM: A Large Language Model for Composed Image Retrieval](http://arxiv.org/abs/2503.19910v1)** | 2025-03-25 | <details><summary>CVPR ...</summary><p>CVPR 2025. Project page: https://collm-cvpr25.github.io/</p></details> |
| **[From My View to Yours: Ego-Augmented Learning in Large Vision Language Models for Understanding Exocentric Daily Living Activities](http://arxiv.org/abs/2501.05711v2)** | 2025-03-25 |  |
| **[CAFe: Unifying Representation and Generation with Contrastive-Autoregressive Finetuning](http://arxiv.org/abs/2503.19900v1)** | 2025-03-25 |  |
| **[FALCONEye: Finding Answers and Localizing Content in ONE-hour-long videos with multi-modal LLMs](http://arxiv.org/abs/2503.19850v1)** | 2025-03-25 |  |
| **[FireEdit: Fine-grained Instruction-based Image Editing via Region-aware Vision Language Model](http://arxiv.org/abs/2503.19839v1)** | 2025-03-25 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model](http://arxiv.org/abs/2406.12030v3)** | 2025-03-25 |  |
| **[ORION: A Holistic End-to-End Autonomous Driving Framework by Vision-Language Instructed Action Generation](http://arxiv.org/abs/2503.19755v1)** | 2025-03-25 |  |
| **[When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning](http://arxiv.org/abs/2503.07588v2)** | 2025-03-25 | <details><summary>12 pa...</summary><p>12 pages, 6 figures, 7 tables</p></details> |
| **[Mind the Gap: Benchmarking Spatial Reasoning in Vision-Language Models](http://arxiv.org/abs/2503.19707v1)** | 2025-03-25 | <details><summary>8 mai...</summary><p>8 main pages, 4 pages Appendix, 5 figures</p></details> |
| **[CLIP-Adapter: Better Vision-Language Models with Feature Adapters](http://arxiv.org/abs/2110.04544v2)** | 2025-03-25 | Accepted by IJCV |
| **[fine-CLIP: Enhancing Zero-Shot Fine-Grained Surgical Action Recognition with Vision-Language Models](http://arxiv.org/abs/2503.19670v1)** | 2025-03-25 | <details><summary>6 pag...</summary><p>6 pages, 3 tables, 3 figures</p></details> |
| **[MC-LLaVA: Multi-Concept Personalized Vision-Language Model](http://arxiv.org/abs/2503.18854v2)** | 2025-03-25 | <details><summary>I sin...</summary><p>I sincerely apologize for any inconvenience caused. We actually uploaded this paper to arXiv in November 2024, as arXiv:2411.11706. During this update, we did not consider the replacement operation of arXiv, which led to duplicate submissions. We have made modifications at the original address arXiv:2411.11706</p></details> |
| **[RGB-Th-Bench: A Dense benchmark for Visual-Thermal Understanding of Vision Language Models](http://arxiv.org/abs/2503.19654v1)** | 2025-03-25 |  |
| **[OpenSDI: Spotting Diffusion-Generated Images in the Open World](http://arxiv.org/abs/2503.19653v1)** | 2025-03-25 |  |
| **[Show or Tell? Effectively prompting Vision-Language Models for semantic segmentation](http://arxiv.org/abs/2503.19647v1)** | 2025-03-25 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks](http://arxiv.org/abs/2410.18387v3)** | 2025-03-25 | <details><summary>Accep...</summary><p>Accepted in ICLR 2025</p></details> |
| **[DomainCQA: Crafting Expert-Level QA from Domain-Specific Charts](http://arxiv.org/abs/2503.19498v1)** | 2025-03-25 | 11 pages, 6 figures |
| **[GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers](http://arxiv.org/abs/2503.19480v1)** | 2025-03-25 | <details><summary>Proje...</summary><p>Project released at: https://mashijie1028.github.io/GenHancer/</p></details> |
| **[Think Before You Segment: High-Quality Reasoning Segmentation with GPT Chain of Thoughts](http://arxiv.org/abs/2503.07503v3)** | 2025-03-25 | <details><summary>Proje...</summary><p>Project page: https://cse.hkust.edu.hk/~skao/thinkfirst.html</p></details> |
| **[RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete](http://arxiv.org/abs/2502.21257v2)** | 2025-03-25 |  |
| **[CalibQuant: 1-Bit KV Cache Quantization for Multimodal LLMs](http://arxiv.org/abs/2502.14882v2)** | 2025-03-24 |  |
| **[MIRAGE: Multimodal Immersive Reasoning and Guided Exploration for Red-Team Jailbreak Attacks](http://arxiv.org/abs/2503.19134v1)** | 2025-03-24 |  |
| **[Visual Position Prompt for MLLM based Visual Grounding](http://arxiv.org/abs/2503.15426v2)** | 2025-03-24 |  |
| **[Beyond Training: Dynamic Token Merging for Zero-Shot Video Understanding](http://arxiv.org/abs/2411.14401v2)** | 2025-03-24 | <details><summary>Code ...</summary><p>Code is available at https://github.com/Jam1ezhang/DYTO</p></details> |
| **[Boosting Virtual Agent Learning and Reasoning: A Step-wise, Multi-dimensional, and Generalist Reward Model with Benchmark](http://arxiv.org/abs/2503.18665v1)** | 2025-03-24 |  |
| **[A Vision Centric Remote Sensing Benchmark](http://arxiv.org/abs/2503.15816v2)** | 2025-03-24 | Under Review |
| **[GUI-World: A Video Benchmark and Dataset for Multimodal GUI-oriented Understanding](http://arxiv.org/abs/2406.10819v2)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted by ICLR 2025</p></details> |
| **[Grounded Chain-of-Thought for Multimodal Large Language Models](http://arxiv.org/abs/2503.12799v2)** | 2025-03-24 |  |
| **[Video-XL-Pro: Reconstructive Token Compression for Extremely Long Video Understanding](http://arxiv.org/abs/2503.18478v1)** | 2025-03-24 |  |
| **[Adapt-$\infty$: Scalable Continual Multimodal Instruction Tuning via Dynamic Data Selection](http://arxiv.org/abs/2410.10636v2)** | 2025-03-24 | <details><summary>First...</summary><p>First two authors contributed equally. Code: https://github.com/adymaharana/adapt-inf</p></details> |

