---
title: Latest 15 Papers - September 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DUAL-VAD: Dual Benchmarks and Anomaly-Focused Sampling for Video Anomaly Detection](http://arxiv.org/abs/2509.11605v2)** | 2025-09-16 | <details><summary>6 pag...</summary><p>6 pages in IEEE double-column format, 1 figure, 5 tables. The paper introduces a unified framework for Video Anomaly Detection (VAD) featuring dual benchmarks and an anomaly-focused sampling strategy</p></details> |
| **[Action Hints: Semantic Typicality and Context Uniqueness for Generalizable Skeleton-based Video Anomaly Detection](http://arxiv.org/abs/2509.11058v1)** | 2025-09-14 |  |
| **[GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation](http://arxiv.org/abs/2509.08232v1)** | 2025-09-10 |  |
| **[Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](http://arxiv.org/abs/2506.18368v3)** | 2025-09-03 | ICCV 2025 Highlight |
| **[MissionHD: Data-Driven Refinement of Reasoning Graph Structure through Hyperdimensional Causal Path Encoding and Decoding](http://arxiv.org/abs/2508.14746v1)** | 2025-08-20 |  |
| **[A Survey on Video Anomaly Detection via Deep Learning: Human, Vehicle, and Environment](http://arxiv.org/abs/2508.14203v1)** | 2025-08-19 |  |
| **[Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](http://arxiv.org/abs/2508.11317v1)** | 2025-08-15 |  |
| **[ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds](http://arxiv.org/abs/2508.09058v1)** | 2025-08-12 |  |
| **[Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection](http://arxiv.org/abs/2508.06318v1)** | 2025-08-08 |  |
| **[HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](http://arxiv.org/abs/2508.00473v1)** | 2025-08-01 |  |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ChronoForge-RL: Chronological Forging through Reinforcement Learning for Enhanced Video Understanding](http://arxiv.org/abs/2509.15800v1)** | 2025-09-19 | 10 pages, 2 figures |
| **[Data-Efficient Learning for Generalizable Surgical Video Understanding](http://arxiv.org/abs/2508.10215v2)** | 2025-09-19 |  |
| **[TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?](http://arxiv.org/abs/2509.15602v1)** | 2025-09-19 |  |
| **[EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery](http://arxiv.org/abs/2509.15596v1)** | 2025-09-19 | <details><summary>Stron...</summary><p>Strong accept by NeurIPS2025 Reviewers and AC, but reject by PC. (Rating: 6,5,4,4)</p></details> |
| **[StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](http://arxiv.org/abs/2505.05467v2)** | 2025-09-18 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[Dense Video Understanding with Gated Residual Tokenization](http://arxiv.org/abs/2509.14199v2)** | 2025-09-18 |  |
| **[Cin√©aste: A Fine-grained Contextual Movie Question Answering Benchmark](http://arxiv.org/abs/2509.14227v1)** | 2025-09-17 | <details><summary>11 pa...</summary><p>11 pages, 5 figures, 5 tables</p></details> |
| **[A Culturally-diverse Multilingual Multimodal Video Benchmark & Model](http://arxiv.org/abs/2506.07032v2)** | 2025-09-17 |  |
| **[ResidualViT for Efficient Temporally Dense Video Encoding](http://arxiv.org/abs/2509.13255v1)** | 2025-09-16 |  |
| **[3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark](http://arxiv.org/abs/2412.07825v4)** | 2025-09-15 | <details><summary>ICCV ...</summary><p>ICCV 2025. Project page: https://3dsrbench.github.io</p></details> |
| **[Open-ended Hierarchical Streaming Video Understanding with Vision Language Models](http://arxiv.org/abs/2509.12145v1)** | 2025-09-15 | 17 pages |
| **[Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding](http://arxiv.org/abs/2509.11866v1)** | 2025-09-15 | 25 pages, 16 figures |
| **[Bridging Vision Language Models and Symbolic Grounding for Video Question Answering](http://arxiv.org/abs/2509.11862v1)** | 2025-09-15 |  |
| **[FineQuest: Adaptive Knowledge-Assisted Sports Video Understanding via Agent-of-Thoughts Reasoning](http://arxiv.org/abs/2509.11796v1)** | 2025-09-15 | ACM MM 2025 |
| **[GLaVE-Cap: Global-Local Aligned Video Captioning with Vision Expert Integration](http://arxiv.org/abs/2509.11360v1)** | 2025-09-14 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning](http://arxiv.org/abs/2502.20587v2)** | 2025-09-19 | <details><summary>EMNLP...</summary><p>EMNLP 2025 Main Conference. Mingyuan, Jize, and Haozhen contributed equally, while Minjia, Chengxiang, and Klara advised equally</p></details> |
| **[Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks](http://arxiv.org/abs/2509.16163v1)** | 2025-09-19 | <details><summary>To be...</summary><p>To be presented as a poster at the Workshop on Safe and Trustworthy Multimodal AI Systems (SafeMM-AI), 2025</p></details> |
| **[LLMs Can Compensate for Deficiencies in Visual Representations](http://arxiv.org/abs/2506.05439v2)** | 2025-09-19 | EMNLP 2025 Findings |
| **[Randomized Smoothing Meets Vision-Language Models](http://arxiv.org/abs/2509.16088v1)** | 2025-09-19 | <details><summary>EMNLP...</summary><p>EMNLP'25 full version, including appendix (proofs, additional experiments)</p></details> |
| **[I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models](http://arxiv.org/abs/2509.16072v1)** | 2025-09-19 |  |
| **[Compose by Focus: Scene Graph-based Atomic Skills](http://arxiv.org/abs/2509.16053v1)** | 2025-09-19 |  |
| **[Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study](http://arxiv.org/abs/2505.15389v2)** | 2025-09-19 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025</p></details> |
| **[CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation](http://arxiv.org/abs/2507.14312v2)** | 2025-09-19 |  |
| **[ViLU: Learning Vision-Language Uncertainties for Failure Prediction](http://arxiv.org/abs/2507.07620v4)** | 2025-09-19 |  |
| **[cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning](http://arxiv.org/abs/2505.22914v2)** | 2025-09-19 |  |
| **[RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding](http://arxiv.org/abs/2508.05244v2)** | 2025-09-19 | <details><summary>Upon ...</summary><p>Upon further review, we identified that our dataset requires optimization to ensure research reliability and accuracy. Additionally, considering the target journal's latest submission policies, we believe comprehensive manuscript revisions are necessary</p></details> |
| **[CIDER: A Causal Cure for Brand-Obsessed Text-to-Image Models](http://arxiv.org/abs/2509.15803v1)** | 2025-09-19 | <details><summary>5 pag...</summary><p>5 pages, 7 figures, submitted to ICASSP2026</p></details> |
| **[Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation](http://arxiv.org/abs/2509.15772v1)** | 2025-09-19 |  |
| **[GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning](http://arxiv.org/abs/2509.15738v1)** | 2025-09-19 |  |
| **[Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models](http://arxiv.org/abs/2503.00743v2)** | 2025-09-19 | <details><summary>39 pa...</summary><p>39 pages, 13 figures. Accept for NeruIPS2025</p></details> |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](http://arxiv.org/abs/2509.16197v1)** | 2025-09-19 |  |
| **[Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models](http://arxiv.org/abs/2509.16149v1)** | 2025-09-19 |  |
| **[BaseReward: A Strong Baseline for Multimodal Reward Model](http://arxiv.org/abs/2509.16127v1)** | 2025-09-19 |  |
| **[See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model](http://arxiv.org/abs/2509.16087v1)** | 2025-09-19 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[Language-Instructed Reasoning for Group Activity Detection via Multimodal Large Language Model](http://arxiv.org/abs/2509.16054v1)** | 2025-09-19 | 9 pages, 5 figures |
| **[EmoQ: Speech Emotion Recognition via Speech-Aware Q-Former and Large Language Model](http://arxiv.org/abs/2509.15775v1)** | 2025-09-19 | 5 pages, 2 figures |
| **[TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?](http://arxiv.org/abs/2509.15602v1)** | 2025-09-19 |  |
| **[EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery](http://arxiv.org/abs/2509.15596v1)** | 2025-09-19 | <details><summary>Stron...</summary><p>Strong accept by NeurIPS2025 Reviewers and AC, but reject by PC. (Rating: 6,5,4,4)</p></details> |
| **[BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent](http://arxiv.org/abs/2509.15566v1)** | 2025-09-19 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2025</p></details> |
| **[OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation](http://arxiv.org/abs/2506.02015v2)** | 2025-09-19 |  |
| **[Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward](http://arxiv.org/abs/2506.07218v2)** | 2025-09-19 |  |
| **[Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models](http://arxiv.org/abs/2509.15478v1)** | 2025-09-18 |  |
| **[Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding](http://arxiv.org/abs/2509.15476v1)** | 2025-09-18 |  |
| **[Efficient Multimodal Dataset Distillation via Generative Models](http://arxiv.org/abs/2509.15472v1)** | 2025-09-18 |  |
| **[Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing](http://arxiv.org/abs/2509.15361v1)** | 2025-09-18 | <details><summary>Accep...</summary><p>Accepted by EMNLP 2025 Findings</p></details> |

