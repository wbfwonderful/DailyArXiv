---
title: Latest 15 Papers - July 02, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis](http://arxiv.org/abs/2506.23648v1)** | 2025-06-30 | <details><summary>10 pa...</summary><p>10 pages, 5 figures, accepted by MICCAI 2025</p></details> |
| **[Autoregressive Denoising Score Matching is a Good Video Anomaly Detector](http://arxiv.org/abs/2506.23282v1)** | 2025-06-29 |  |
| **[Privacy-Preserving Video Anomaly Detection: A Survey](http://arxiv.org/abs/2411.14565v2)** | 2025-06-28 | <details><summary>22 pa...</summary><p>22 pages, 9 figures, 7 tables</p></details> |
| **[Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](http://arxiv.org/abs/2506.18368v1)** | 2025-06-23 |  |
| **[Learning Event Completeness for Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2506.13095v1)** | 2025-06-16 | Accepted by ICML |
| **[SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models](http://arxiv.org/abs/2506.12992v1)** | 2025-06-15 | <details><summary>CVPR ...</summary><p>CVPR 2025 Workshop: VAND 3.0 - Visual Anomaly and Novelty Detection</p></details> |
| **[Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation](http://arxiv.org/abs/2506.11777v1)** | 2025-06-13 |  |
| **[A Lightweight Dual-Branch System for Weakly-Supervised Video Anomaly Detection on Consumer Edge Devices](http://arxiv.org/abs/2410.21991v7)** | 2025-06-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE TCE and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Track Any Anomalous Object: A Granular Video Anomaly Detection Pipeline](http://arxiv.org/abs/2506.05175v1)** | 2025-06-05 |  |
| **[MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection](http://arxiv.org/abs/2506.02535v2)** | 2025-06-04 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v2)** | 2025-05-31 | <details><summary>12 pa...</summary><p>12 pages, 6 figures, 9 tables. This work has been submitted to the IEEE for possible publication</p></details> |
| **[ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications](http://arxiv.org/abs/2505.02179v2)** | 2025-05-29 | <details><summary>arXiv...</summary><p>arXiv admin comment: This version has been removed by arXiv administrators as the submitter did not have the rights to agree to the license at the time of submission</p></details> |
| **[Vad-R1: Towards Video Anomaly Reasoning via Perception-to-Cognition Chain-of-Thought](http://arxiv.org/abs/2505.19877v1)** | 2025-05-26 | 9 pages, 4 figures |
| **[Rethinking Metrics and Benchmarks of Video Anomaly Detection](http://arxiv.org/abs/2505.19022v1)** | 2025-05-25 |  |
| **[MissionGNN: Hierarchical Multimodal GNN-based Weakly Supervised Video Anomaly Recognition with Mission-Specific Knowledge Graph Generation](http://arxiv.org/abs/2406.18815v3)** | 2025-05-23 | <details><summary>Accep...</summary><p>Accepted to WACV 2025</p></details> |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](http://arxiv.org/abs/2506.23825v1)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[InstructionBench: An Instructional Video Understanding Benchmark](http://arxiv.org/abs/2504.05040v2)** | 2025-06-30 |  |
| **[MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition](http://arxiv.org/abs/2506.23283v1)** | 2025-06-29 | ICML 2025 paper |
| **[Time-R1: Post-Training Large Vision Language Model for Temporal Video Grounding](http://arxiv.org/abs/2503.13377v3)** | 2025-06-29 | <details><summary>Proje...</summary><p>Project Page: https://xuboshen.github.io/Time-R1/</p></details> |
| **[ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment](http://arxiv.org/abs/2506.22967v1)** | 2025-06-28 | <details><summary>Prepr...</summary><p>Preprint manuscript - Project page: https://github.com/aghdamamir/act-align</p></details> |
| **[APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval](http://arxiv.org/abs/2506.04953v2)** | 2025-06-28 |  |
| **[Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs](http://arxiv.org/abs/2506.22139v1)** | 2025-06-27 | <details><summary>Accep...</summary><p>Accepted at ICCV 2025</p></details> |
| **[Self-ReS: Self-Reflection in Large Vision-Language Models for Long Video Understanding](http://arxiv.org/abs/2503.20362v2)** | 2025-06-27 |  |
| **[LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs](http://arxiv.org/abs/2506.21862v1)** | 2025-06-27 | <details><summary>21 pa...</summary><p>21 pages, 4 figures, 7 tables</p></details> |
| **[Task-Aware KV Compression For Cost-Effective Long Video Understanding](http://arxiv.org/abs/2506.21184v1)** | 2025-06-26 | <details><summary>14 pa...</summary><p>14 pages, 3 figures, 6 tables</p></details> |
| **[IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes](http://arxiv.org/abs/2506.21116v1)** | 2025-06-26 |  |
| **[HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics](http://arxiv.org/abs/2408.17443v4)** | 2025-06-26 | <details><summary>Accep...</summary><p>Accepted for ICCV 2025. Project page: https://joslefaure.github.io/assets/html/hermes.html</p></details> |
| **[PEVLM: Parallel Encoding for Vision-Language Models](http://arxiv.org/abs/2506.19651v1)** | 2025-06-24 |  |
| **[Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification](http://arxiv.org/abs/2506.19225v1)** | 2025-06-24 | <details><summary>12 pa...</summary><p>12 pages, 5 Figure, 3 Table</p></details> |
| **[Universal Video Temporal Grounding with Generative Multi-modal Large Language Models](http://arxiv.org/abs/2506.18883v1)** | 2025-06-23 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs](http://arxiv.org/abs/2506.18985v2)** | 2025-06-30 |  |
| **[EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations](http://arxiv.org/abs/2506.24016v1)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted at ACL 2025 Findings</p></details> |
| **[The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models](http://arxiv.org/abs/2506.24000v1)** | 2025-06-30 | <details><summary>Githu...</summary><p>Github link: https://github.com/TomSheng21/tta-vlm</p></details> |
| **[GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models](http://arxiv.org/abs/2506.23903v1)** | 2025-06-30 | <details><summary>11 pa...</summary><p>11 pages, 3 figures, 6 figures</p></details> |
| **[Advancing Textual Prompt Learning with Anchored Attributes](http://arxiv.org/abs/2412.09442v2)** | 2025-06-30 | <details><summary>ICCV ...</summary><p>ICCV 2025. Project Page: https://zhengli97.github.io/ATPrompt/</p></details> |
| **[A Closer Look at Conditional Prompt Tuning for Vision-Language Models](http://arxiv.org/abs/2506.23856v1)** | 2025-06-30 | 18 pages |
| **[Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model](http://arxiv.org/abs/2506.23822v1)** | 2025-06-30 | Accepted to ICCV'25 |
| **[Visual Textualization for Image Prompted Object Detection](http://arxiv.org/abs/2506.23785v1)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?](http://arxiv.org/abs/2506.23725v1)** | 2025-06-30 |  |
| **[On the Domain Robustness of Contrastive Vision-Language Models](http://arxiv.org/abs/2506.23663v1)** | 2025-06-30 | <details><summary>Deepb...</summary><p>Deepbench is available at https://github.com/ml-lab-htw/deepbench</p></details> |
| **[TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks](http://arxiv.org/abs/2505.12884v2)** | 2025-06-30 |  |
| **[CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models](http://arxiv.org/abs/2506.23590v1)** | 2025-06-30 |  |
| **[A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation](http://arxiv.org/abs/2506.23584v1)** | 2025-06-30 |  |
| **[Generalizing vision-language models to novel domains: A comprehensive survey](http://arxiv.org/abs/2506.18504v2)** | 2025-06-30 |  |
| **[Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding](http://arxiv.org/abs/2506.23491v1)** | 2025-06-30 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World](http://arxiv.org/abs/2506.24102v1)** | 2025-06-30 | <details><summary>Datas...</summary><p>Datasets and Models: https://github.com/lxtGH/DenseWorld-1M</p></details> |
| **[A Survey on Vision-Language-Action Models for Autonomous Driving](http://arxiv.org/abs/2506.24044v1)** | 2025-06-30 |  |
| **[Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs](http://arxiv.org/abs/2506.23940v1)** | 2025-06-30 |  |
| **[Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](http://arxiv.org/abs/2506.23825v1)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment](http://arxiv.org/abs/2412.19326v2)** | 2025-06-30 | CVPR2025 |
| **[FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers](http://arxiv.org/abs/2501.16297v2)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted to the IEEE/CVF International Conference on Computer Vision (ICCV) 2025</p></details> |
| **[Unified Multimodal Understanding via Byte-Pair Visual Encoding](http://arxiv.org/abs/2506.23639v1)** | 2025-06-30 |  |
| **[BIMgent: Towards Autonomous Building Modeling via Computer-use Agents](http://arxiv.org/abs/2506.07217v2)** | 2025-06-30 | <details><summary>ICML ...</summary><p>ICML 2025 Workshop on Computer Use Agents</p></details> |
| **[Visual Position Prompt for MLLM based Visual Grounding](http://arxiv.org/abs/2503.15426v3)** | 2025-06-30 |  |
| **[MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI](http://arxiv.org/abs/2506.23563v1)** | 2025-06-30 | Technical report |
| **[OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM](http://arxiv.org/abs/2504.04801v2)** | 2025-06-30 |  |
| **[Generalizing vision-language models to novel domains: A comprehensive survey](http://arxiv.org/abs/2506.18504v2)** | 2025-06-30 |  |
| **[Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably](http://arxiv.org/abs/2506.23508v1)** | 2025-06-30 | <details><summary>18 pa...</summary><p>18 pages (Preprint. Work in progress)</p></details> |
| **[Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks](http://arxiv.org/abs/2506.23481v1)** | 2025-06-30 |  |
| **[Scaling Laws for Black box Adversarial Attacks](http://arxiv.org/abs/2411.16782v3)** | 2025-06-29 |  |

