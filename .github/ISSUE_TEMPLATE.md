---
title: Latest 15 Papers - April 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches](http://arxiv.org/abs/2504.14753v1)** | 2025-04-20 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Image Processing (TIP)</p></details> |
| **[EventVAD: Training-Free Event-Aware Video Anomaly Detection](http://arxiv.org/abs/2504.13092v1)** | 2025-04-17 |  |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |
| **[AssistPDA: An Online Video Surveillance Assistant for Video Anomaly Prediction, Detection, and Analysis](http://arxiv.org/abs/2503.21904v1)** | 2025-03-27 | 13 pages |
| **[VADMamba: Exploring State Space Models for Fast Video Anomaly Detection](http://arxiv.org/abs/2503.21169v1)** | 2025-03-27 | <details><summary>Accpe...</summary><p>Accpeted by ICME 2025</p></details> |
| **[Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection](http://arxiv.org/abs/2412.03044v2)** | 2025-03-27 |  |
| **[Video Anomaly Detection with Contours -- A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |
| **[Anomize: Better Open Vocabulary Video Anomaly Detection](http://arxiv.org/abs/2503.18094v1)** | 2025-03-23 |  |
| **[Towards Adaptive Human-centric Video Anomaly Detection: A Comprehensive Framework and A New Benchmark](http://arxiv.org/abs/2408.14329v2)** | 2025-03-19 |  |
| **[Human-Centric Video Anomaly Detection Through Spatio-Temporal Pose Tokenization and Transformer](http://arxiv.org/abs/2408.15185v2)** | 2025-03-17 |  |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models](http://arxiv.org/abs/2504.15271v1)** | 2025-04-21 |  |
| **[An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes](http://arxiv.org/abs/2504.15270v1)** | 2025-04-21 |  |
| **[Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation](http://arxiv.org/abs/2504.02438v3)** | 2025-04-21 |  |
| **[PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of Complex Videos in the Wild](http://arxiv.org/abs/2504.11326v2)** | 2025-04-21 | <details><summary>Works...</summary><p>Workshop Page: https://pvuw.github.io/. arXiv admin note: text overlap with arXiv:2504.00476, arXiv:2504.05178</p></details> |
| **[OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding](http://arxiv.org/abs/2504.14692v1)** | 2025-04-20 |  |
| **[Grounding-MD: Grounded Video-language Pre-training for Open-World Moment Detection](http://arxiv.org/abs/2504.14553v1)** | 2025-04-20 |  |
| **[Are Vision LLMs Road-Ready? A Comprehensive Benchmark for Safety-Critical Driving Video Understanding](http://arxiv.org/abs/2504.14526v1)** | 2025-04-20 |  |
| **[ResNetVLLM -- Multi-modal Vision LLM for the Video Understanding Task](http://arxiv.org/abs/2504.14432v1)** | 2025-04-20 |  |
| **[How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?](http://arxiv.org/abs/2504.14391v1)** | 2025-04-19 |  |
| **[3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark](http://arxiv.org/abs/2412.07825v2)** | 2025-04-19 | <details><summary>Proje...</summary><p>Project page: https://3dsrbench.github.io</p></details> |
| **[Perception Encoder: The best visual embeddings are not at the output of the network](http://arxiv.org/abs/2504.13181v1)** | 2025-04-17 | Initial Submission |
| **[PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding](http://arxiv.org/abs/2504.13180v1)** | 2025-04-17 | Technical report |
| **[VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference Optimization for Large Video Models](http://arxiv.org/abs/2504.13122v1)** | 2025-04-17 | <details><summary>Code ...</summary><p>Code and Data: https://github.com/HaroldChen19/VistaDPO</p></details> |
| **[Prototypes are Balanced Units for Efficient and Effective Partially Relevant Video Retrieval](http://arxiv.org/abs/2504.13035v1)** | 2025-04-17 |  |
| **[Online Video Understanding: OVBench and VideoChat-Online](http://arxiv.org/abs/2501.00584v2)** | 2025-04-17 | <details><summary>CVPR ...</summary><p>CVPR 2025 Camera Ready Version. Project Page: https://videochat-online.github.io</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models](http://arxiv.org/abs/2504.15271v1)** | 2025-04-21 |  |
| **[Analysing the Robustness of Vision-Language-Models to Common Corruptions](http://arxiv.org/abs/2504.13690v2)** | 2025-04-21 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2304.10592, arXiv:2301.12597 by other authors</p></details> |
| **[HiddenDetect: Detecting Jailbreak Attacks against Large Vision-Language Models via Monitoring Hidden States](http://arxiv.org/abs/2502.14744v3)** | 2025-04-21 |  |
| **[Tree of Attributes Prompt Learning for Vision-Language Models](http://arxiv.org/abs/2410.11201v2)** | 2025-04-21 |  |
| **[Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation](http://arxiv.org/abs/2504.02438v3)** | 2025-04-21 |  |
| **[KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking](http://arxiv.org/abs/2504.15135v1)** | 2025-04-21 | SIGIR 2025 (Short) |
| **[GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding](http://arxiv.org/abs/2503.10596v2)** | 2025-04-21 | <details><summary>Work ...</summary><p>Work in progress. Code: https://github.com/hustvl/GroundingSuite. Update: add more results & polish the report</p></details> |
| **[A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs](http://arxiv.org/abs/2501.13620v3)** | 2025-04-21 |  |
| **[Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters](http://arxiv.org/abs/2411.03312v2)** | 2025-04-21 | <details><summary>Publi...</summary><p>Published at ICLR 2025</p></details> |
| **[Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A Comprehensive Evaluation](http://arxiv.org/abs/2504.14988v1)** | 2025-04-21 |  |
| **[AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection](http://arxiv.org/abs/2310.18961v9)** | 2025-04-21 | <details><summary>Accep...</summary><p>Accepted by ICLR 2024</p></details> |
| **[VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform](http://arxiv.org/abs/2504.14904v1)** | 2025-04-21 | 20 pages, 6 figures |
| **[Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation](http://arxiv.org/abs/2504.14848v1)** | 2025-04-21 |  |
| **[OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding](http://arxiv.org/abs/2504.14692v1)** | 2025-04-20 |  |
| **[MedM-VL: What Makes a Good Medical LVLM?](http://arxiv.org/abs/2504.04323v2)** | 2025-04-20 |  |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models](http://arxiv.org/abs/2504.15279v1)** | 2025-04-21 | <details><summary>Code,...</summary><p>Code, data, and baselines are available at https://visulogic-benchmark.github.io/VisuLogic</p></details> |
| **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v3)** | 2025-04-21 |  |
| **[A Call for New Recipes to Enhance Spatial Reasoning in MLLMs](http://arxiv.org/abs/2504.15037v1)** | 2025-04-21 |  |
| **[GeoNav: Empowering MLLMs with Explicit Geospatial Reasoning Abilities for Language-Goal Aerial Navigation](http://arxiv.org/abs/2504.09587v2)** | 2025-04-21 |  |
| **[Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens](http://arxiv.org/abs/2504.14666v1)** | 2025-04-20 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025 (Oral)</p></details> |
| **[UFO2: The Desktop AgentOS](http://arxiv.org/abs/2504.14603v1)** | 2025-04-20 | <details><summary>The s...</summary><p>The source code of UFO2 is publicly available at https://github.com/microsoft/UFO/, with comprehensive documentation provided at https://microsoft.github.io/UFO/</p></details> |
| **[Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction](http://arxiv.org/abs/2504.14588v1)** | 2025-04-20 | Accepted by CVPR2025 |
| **[FUSION: Fully Integration of Vision-Language Representations for Deep Cross-Modal Understanding](http://arxiv.org/abs/2504.09925v2)** | 2025-04-19 |  |
| **[Manipulating Multimodal Agents via Cross-Modal Prompt Injection](http://arxiv.org/abs/2504.14348v1)** | 2025-04-19 | 17 pages, 4 figures |
| **[Assessing and Learning Alignment of Unimodal Vision and Language Models](http://arxiv.org/abs/2412.04616v2)** | 2025-04-19 | CVPR 2025 Highlight |
| **[ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images](http://arxiv.org/abs/2502.05928v3)** | 2025-04-19 |  |
| **[InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners](http://arxiv.org/abs/2504.14239v1)** | 2025-04-19 | <details><summary>10 pa...</summary><p>10 pages, 3 figures, work in progress</p></details> |
| **[SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models](http://arxiv.org/abs/2402.04178v2)** | 2025-04-19 | <details><summary>Accep...</summary><p>Accepted by Visual Intelligence</p></details> |
| **[InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models](http://arxiv.org/abs/2504.10479v3)** | 2025-04-19 | Technical Report |
| **[Scaling LLaNA: Advancing NeRF-Language Understanding Through Large-Scale Training](http://arxiv.org/abs/2504.13995v1)** | 2025-04-18 | <details><summary>Under...</summary><p>Under submission. Project page at https://andreamaduzzi.github.io/llana/</p></details> |

