---
title: Latest 15 Papers - March 28, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v3)** | 2025-03-26 | <details><summary>Revis...</summary><p>Revised to ACM Computing Surveys, under review, for more information and supplementary material, please see https://github.com/fdjingliu/NSVAD</p></details> |
| **[Video Anomaly Detection with Contours - A Study](http://arxiv.org/abs/2503.19588v1)** | 2025-03-25 |  |
| **[CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos](http://arxiv.org/abs/2503.18808v1)** | 2025-03-24 | <details><summary>Accep...</summary><p>Accepted for publication by IEEE Transactions on Image Processing</p></details> |
| **[Anomize: Better Open Vocabulary Video Anomaly Detection](http://arxiv.org/abs/2503.18094v1)** | 2025-03-23 |  |
| **[Towards Adaptive Human-centric Video Anomaly Detection: A Comprehensive Framework and A New Benchmark](http://arxiv.org/abs/2408.14329v2)** | 2025-03-19 |  |
| **[Human-Centric Video Anomaly Detection Through Spatio-Temporal Pose Tokenization and Transformer](http://arxiv.org/abs/2408.15185v2)** | 2025-03-17 |  |
| **[Language-guided Open-world Video Anomaly Detection](http://arxiv.org/abs/2503.13160v1)** | 2025-03-17 |  |
| **[UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks](http://arxiv.org/abs/2503.12905v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted by AAAI 2025</p></details> |
| **[Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos](http://arxiv.org/abs/2503.07799v1)** | 2025-03-10 |  |
| **[Dual Conditioned Motion Diffusion for Pose-Based Video Anomaly Detection](http://arxiv.org/abs/2412.17210v2)** | 2025-03-08 | <details><summary>Code ...</summary><p>Code is on https://github.com/guijiejie/DCMD-main</p></details> |
| **[Video Anomaly Detection with Structured Keywords](http://arxiv.org/abs/2503.10653v1)** | 2025-03-07 |  |
| **[AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM](http://arxiv.org/abs/2503.04504v1)** | 2025-03-06 |  |
| **[Anomaly detection in non-stationary videos using time-recursive differencing network based prediction](http://arxiv.org/abs/2503.02234v1)** | 2025-03-04 | <details><summary>Copyr...</summary><p>Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Transformer Based Self-Context Aware Prediction for Few-Shot Anomaly Detection in Videos](http://arxiv.org/abs/2503.00670v1)** | 2025-03-02 | <details><summary>Copyr...</summary><p>Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion](http://arxiv.org/abs/2410.01506v4)** | 2025-02-28 | <details><summary>Accep...</summary><p>Accepted at the Thirteenth International Conference on Learning Representations (ICLR 2025)</p></details> |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Trial to Triumph: Advancing Long Video Understanding via Visual Context Sample Scaling and Self-reward Alignment](http://arxiv.org/abs/2503.20472v1)** | 2025-03-26 |  |
| **[Self-ReS: Self-Reflection in Large Vision-Language Models for Long Video Understanding](http://arxiv.org/abs/2503.20362v1)** | 2025-03-26 |  |
| **[Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection](http://arxiv.org/abs/2503.03562v3)** | 2025-03-26 | Accepted by CVPR25 |
| **[Progress-Aware Video Frame Captioning](http://arxiv.org/abs/2412.02071v2)** | 2025-03-26 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025, Project website: https://vision.cs.utexas.edu/projects/ProgressCaptioner/</p></details> |
| **[HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding](http://arxiv.org/abs/2501.01645v2)** | 2025-03-26 | <details><summary>Accep...</summary><p>Accepted to ICME 2025</p></details> |
| **[LLAVIDAL: A Large LAnguage VIsion Model for Daily Activities of Living](http://arxiv.org/abs/2406.09390v3)** | 2025-03-25 | <details><summary>CVPR ...</summary><p>CVPR 2025 Camera Ready</p></details> |
| **[From My View to Yours: Ego-Augmented Learning in Large Vision Language Models for Understanding Exocentric Daily Living Activities](http://arxiv.org/abs/2501.05711v2)** | 2025-03-25 |  |
| **[ACVUBench: Audio-Centric Video Understanding Benchmark](http://arxiv.org/abs/2503.19951v1)** | 2025-03-25 |  |
| **[PAVE: Patching and Adapting Video Large Language Models](http://arxiv.org/abs/2503.19794v1)** | 2025-03-25 | <details><summary>CVPR2...</summary><p>CVPR2025 Camera Ready</p></details> |
| **[Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations](http://arxiv.org/abs/2503.19706v1)** | 2025-03-25 | <details><summary>CVPR ...</summary><p>CVPR 2025 Camera-ready</p></details> |
| **[Exploring Hallucination of Large Multimodal Models in Video Understanding: Benchmark, Analysis and Mitigation](http://arxiv.org/abs/2503.19622v1)** | 2025-03-25 |  |
| **[DynFocus: Dynamic Cooperative Network Empowers LLMs with Video Understanding](http://arxiv.org/abs/2411.12355v2)** | 2025-03-25 | Accepted by CVPR 25 |
| **[Lost in Time: A New Temporal Benchmark for VideoLLMs](http://arxiv.org/abs/2410.07752v3)** | 2025-03-25 |  |
| **[VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM](http://arxiv.org/abs/2501.00599v3)** | 2025-03-25 | <details><summary>17 pa...</summary><p>17 pages, 14 figures, technical report</p></details> |
| **[STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding](http://arxiv.org/abs/2503.15973v2)** | 2025-03-25 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning](http://arxiv.org/abs/2503.20752v1)** | 2025-03-26 | 35 pages, 22 figures |
| **[MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion](http://arxiv.org/abs/2503.20698v1)** | 2025-03-26 |  |
| **[Data Augmentation in Earth Observation: A Diffusion Model Approach](http://arxiv.org/abs/2406.06218v2)** | 2025-03-26 | 25 pages, 12 figures |
| **[COSMOS: Cross-Modality Self-Distillation for Vision Language Pre-training](http://arxiv.org/abs/2412.01814v2)** | 2025-03-26 | CVPR 2025 |
| **[AutoRad-Lung: A Radiomic-Guided Prompting Autoregressive Vision-Language Model for Lung Nodule Malignancy Prediction](http://arxiv.org/abs/2503.20662v1)** | 2025-03-26 |  |
| **[MC-LLaVA: Multi-Concept Personalized Vision-Language Model](http://arxiv.org/abs/2411.11706v3)** | 2025-03-26 |  |
| **[IAP: Improving Continual Learning of Vision-Language Models via Instance-Aware Prompting](http://arxiv.org/abs/2503.20612v1)** | 2025-03-26 | <details><summary>Code ...</summary><p>Code can be found at https://github.com/FerdinandZJU/IAP</p></details> |
| **[Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models](http://arxiv.org/abs/2503.20492v1)** | 2025-03-26 | preprint |
| **[Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection](http://arxiv.org/abs/2503.14754v2)** | 2025-03-26 | In review |
| **[Aligning Visual Contrastive learning models via Preference Optimization](http://arxiv.org/abs/2411.08923v3)** | 2025-03-26 |  |
| **[PHT-CAD: Efficient CAD Parametric Primitive Analysis with Progressive Hierarchical Tuning](http://arxiv.org/abs/2503.18147v2)** | 2025-03-26 |  |
| **[Self-ReS: Self-Reflection in Large Vision-Language Models for Long Video Understanding](http://arxiv.org/abs/2503.20362v1)** | 2025-03-26 |  |
| **[NLPrompt: Noise-Label Prompt Learning for Vision-Language Models](http://arxiv.org/abs/2412.01256v2)** | 2025-03-26 |  |
| **[Does GenAI Make Usability Testing Obsolete?](http://arxiv.org/abs/2411.00634v2)** | 2025-03-26 | <details><summary>Accep...</summary><p>Accepted for publication at The 47th IEEE/ACM International Conference on Software Engineering ICSE 2025</p></details> |
| **[MMRL: Multi-Modal Representation Learning for Vision-Language Models](http://arxiv.org/abs/2503.08497v2)** | 2025-03-26 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025</p></details> |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MATHGLANCE: Multimodal Large Language Models Do Not Know Where to Look in Mathematical Diagrams](http://arxiv.org/abs/2503.20745v1)** | 2025-03-26 |  |
| **[Mitigating Low-Level Visual Hallucinations Requires Self-Awareness: Database, Model and Training Strategy](http://arxiv.org/abs/2503.20673v1)** | 2025-03-26 |  |
| **[Vision-Amplified Semantic Entropy for Hallucination Detection in Medical Visual Question Answering](http://arxiv.org/abs/2503.20504v1)** | 2025-03-26 | 11 pages, 2 figures |
| **[MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation](http://arxiv.org/abs/2503.20384v1)** | 2025-03-26 |  |
| **[Dynamic Pyramid Network for Efficient Multimodal Large Language Model](http://arxiv.org/abs/2503.20322v1)** | 2025-03-26 |  |
| **[Instruction-Oriented Preference Alignment for Enhancing Multi-Modal Comprehension Capability of MLLMs](http://arxiv.org/abs/2503.20309v1)** | 2025-03-26 | Technical report |
| **[HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding](http://arxiv.org/abs/2501.01645v2)** | 2025-03-26 | <details><summary>Accep...</summary><p>Accepted to ICME 2025</p></details> |
| **[LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?](http://arxiv.org/abs/2503.19990v1)** | 2025-03-25 | 12 pages, 7 figures |
| **[Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks](http://arxiv.org/abs/2410.18387v3)** | 2025-03-25 | <details><summary>Accep...</summary><p>Accepted in ICLR 2025</p></details> |
| **[DomainCQA: Crafting Expert-Level QA from Domain-Specific Charts](http://arxiv.org/abs/2503.19498v1)** | 2025-03-25 | 11 pages, 6 figures |
| **[GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers](http://arxiv.org/abs/2503.19480v1)** | 2025-03-25 | <details><summary>Proje...</summary><p>Project released at: https://mashijie1028.github.io/GenHancer/</p></details> |
| **[Think Before You Segment: High-Quality Reasoning Segmentation with GPT Chain of Thoughts](http://arxiv.org/abs/2503.07503v3)** | 2025-03-25 | <details><summary>Proje...</summary><p>Project page: https://cse.hkust.edu.hk/~skao/thinkfirst.html</p></details> |
| **[RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete](http://arxiv.org/abs/2502.21257v2)** | 2025-03-25 |  |
| **[CalibQuant: 1-Bit KV Cache Quantization for Multimodal LLMs](http://arxiv.org/abs/2502.14882v2)** | 2025-03-24 |  |
| **[MIRAGE: Multimodal Immersive Reasoning and Guided Exploration for Red-Team Jailbreak Attacks](http://arxiv.org/abs/2503.19134v1)** | 2025-03-24 |  |

