---
title: Latest 15 Papers - May 30, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Anomaly Detection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Vad-R1: Towards Video Anomaly Reasoning via Perception-to-Cognition Chain-of-Thought](http://arxiv.org/abs/2505.19877v1)** | 2025-05-26 | 9 pages, 4 figures |
| **[Rethinking Metrics and Benchmarks of Video Anomaly Detection](http://arxiv.org/abs/2505.19022v1)** | 2025-05-25 |  |
| **[MissionGNN: Hierarchical Multimodal GNN-based Weakly Supervised Video Anomaly Recognition with Mission-Specific Knowledge Graph Generation](http://arxiv.org/abs/2406.18815v3)** | 2025-05-23 | <details><summary>Accep...</summary><p>Accepted to WACV 2025</p></details> |
| **[Flashback: Memory-Driven Zero-shot, Real-time Video Anomaly Detection](http://arxiv.org/abs/2505.15205v2)** | 2025-05-23 | 12 pages, 5 figures |
| **[Just Dance with $Ï€$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection](http://arxiv.org/abs/2505.13123v1)** | 2025-05-19 |  |
| **[Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection](http://arxiv.org/abs/2505.02393v2)** | 2025-05-08 |  |
| **[ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications](http://arxiv.org/abs/2505.02179v1)** | 2025-05-04 |  |
| **[Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving](http://arxiv.org/abs/2406.06423v3)** | 2025-04-28 | <details><summary>Danie...</summary><p>Daniel Bogdoll and Jan Imhof contributed equally. Accepted for publication at BMVC 2024 RROW workshop. Won Best Paper Award</p></details> |
| **[Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches](http://arxiv.org/abs/2504.14753v1)** | 2025-04-20 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Image Processing (TIP)</p></details> |
| **[EventVAD: Training-Free Event-Aware Video Anomaly Detection](http://arxiv.org/abs/2504.13092v1)** | 2025-04-17 |  |
| **[SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model](http://arxiv.org/abs/2504.10320v1)** | 2025-04-14 |  |
| **[AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection](http://arxiv.org/abs/2504.04495v1)** | 2025-04-06 | <details><summary>11 pa...</summary><p>11 pages, 4 figures, 6 tables</p></details> |
| **[From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection](http://arxiv.org/abs/2410.21991v6)** | 2025-04-06 | <details><summary>This ...</summary><p>This manuscript has been submitted to IEEE Transactions on Circuits and Systems for Video Technology and is under consideration for publication, with potential copyright transfer in the future</p></details> |
| **[Networking Systems for Video Anomaly Detection: A Tutorial and Survey](http://arxiv.org/abs/2405.10347v4)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted to ACM Computing Surveys. For more information and supplementary material, please visit https://github.com/fdjingliu/NSVAD</p></details> |
| **[VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](http://arxiv.org/abs/2412.01095v3)** | 2025-03-31 | <details><summary>Accep...</summary><p>Accepted in CVPR 2025</p></details> |

## Video Understanding
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Universal Visuo-Tactile Video Understanding for Embodied Interaction](http://arxiv.org/abs/2505.22566v1)** | 2025-05-28 | 13 pages, 5 figures |
| **[FocusChat: Text-guided Long Video Understanding via Spatiotemporal Information Filtering](http://arxiv.org/abs/2412.12833v2)** | 2025-05-28 | 11 pages, 4 figures |
| **[Semantics-aware Test-time Adaptation for 3D Human Pose Estimation](http://arxiv.org/abs/2502.10724v2)** | 2025-05-28 | 10 pages, 4 figures |
| **[Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding](http://arxiv.org/abs/2505.18079v2)** | 2025-05-28 | <details><summary>V2 dr...</summary><p>V2 draft. Under review</p></details> |
| **[LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models](http://arxiv.org/abs/2502.02406v3)** | 2025-05-27 |  |
| **[HuMoCon: Concept Discovery for Human Motion Understanding](http://arxiv.org/abs/2505.20920v1)** | 2025-05-27 | 18 pages, 10 figures |
| **[MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding](http://arxiv.org/abs/2505.20715v1)** | 2025-05-27 |  |
| **[H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding](http://arxiv.org/abs/2503.24008v2)** | 2025-05-27 |  |
| **[HoPE: Hybrid of Position Embedding for Length Generalization in Vision-Language Models](http://arxiv.org/abs/2505.20444v1)** | 2025-05-26 |  |
| **[Time-R1: Post-Training Large Vision Language Model for Temporal Video Grounding](http://arxiv.org/abs/2503.13377v2)** | 2025-05-26 | <details><summary>Proje...</summary><p>Project Page: https://xuboshen.github.io/Time-R1/</p></details> |
| **[TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos](http://arxiv.org/abs/2505.20124v1)** | 2025-05-26 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025 Main. Project page: https://friedrichor.github.io/projects/TUNA</p></details> |
| **[AdaTP: Attention-Debiased Token Pruning for Video Large Language Models](http://arxiv.org/abs/2505.20100v1)** | 2025-05-26 |  |
| **[WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs](http://arxiv.org/abs/2502.04326v2)** | 2025-05-26 |  |
| **[Two Causally Related Needles in a Video Haystack](http://arxiv.org/abs/2505.19853v1)** | 2025-05-26 |  |
| **[FastVID: Dynamic Density Pruning for Fast Video Large Language Models](http://arxiv.org/abs/2503.11187v2)** | 2025-05-26 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Zero-Shot Vision Encoder Grafting via LLM Surrogates](http://arxiv.org/abs/2505.22664v1)** | 2025-05-28 | 15 pages |
| **[Training Free Stylized Abstraction](http://arxiv.org/abs/2505.22663v1)** | 2025-05-28 | <details><summary>Proje...</summary><p>Project Page: https://kartik-3004.github.io/TF-SA/</p></details> |
| **[VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models](http://arxiv.org/abs/2505.22654v1)** | 2025-05-28 |  |
| **[Sherlock: Self-Correcting Reasoning in Vision-Language Models](http://arxiv.org/abs/2505.22651v1)** | 2025-05-28 | 27 pages |
| **[VTool-R1: VLMs Learn to Think with Images via Reinforcement Learning on Multimodal Tool Use](http://arxiv.org/abs/2505.19255v2)** | 2025-05-28 |  |
| **[VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Vision-Language Models](http://arxiv.org/abs/2505.20718v2)** | 2025-05-28 |  |
| **[Hypothesis Testing in Imaging Inverse Problems](http://arxiv.org/abs/2505.22481v1)** | 2025-05-28 |  |
| **[Zero-Shot 3D Visual Grounding from Vision-Language Models](http://arxiv.org/abs/2505.22429v1)** | 2025-05-28 | <details><summary>3D-LL...</summary><p>3D-LLM/VLA @ CVPR 2025; Project Page at https://seeground.github.io/</p></details> |
| **[IKIWISI: An Interactive Visual Pattern Generator for Evaluating the Reliability of Vision-Language Models Without Ground Truth](http://arxiv.org/abs/2505.22305v1)** | 2025-05-28 | <details><summary>Accep...</summary><p>Accepted at DIS'25 (Funchal, Portugal)</p></details> |
| **[HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment](http://arxiv.org/abs/2503.23907v2)** | 2025-05-28 |  |
| **[Interpreting CLIP with Hierarchical Sparse Autoencoders](http://arxiv.org/abs/2502.20578v2)** | 2025-05-28 |  |
| **[Investigating Mechanisms for In-Context Vision Language Binding](http://arxiv.org/abs/2505.22200v1)** | 2025-05-28 | <details><summary>Accep...</summary><p>Accepted to MIV at CVPRW 2025 (Oral)</p></details> |
| **[Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging](http://arxiv.org/abs/2505.22150v1)** | 2025-05-28 | CogSci2025 |
| **[3D Question Answering via only 2D Vision-Language Models](http://arxiv.org/abs/2505.22143v1)** | 2025-05-28 | ICML2025 |
| **[Visuospatial Cognitive Assistant](http://arxiv.org/abs/2505.12312v3)** | 2025-05-28 | <details><summary>Autho...</summary><p>Author list corrected. In version 1, Hidetoshi Shimodaira was included as a co-author without their consent and has been removed from the author list</p></details> |

## Multimodal Large Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Spatial Knowledge Graph-Guided Multimodal Synthesis](http://arxiv.org/abs/2505.22633v1)** | 2025-05-28 | Ongoing work |
| **[RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction](http://arxiv.org/abs/2505.22613v1)** | 2025-05-28 | <details><summary>code:...</summary><p>code: https://github.com/wangyuchi369/RICO</p></details> |
| **[Multi-MLLM Knowledge Distillation for Out-of-Context News Detection](http://arxiv.org/abs/2505.22517v1)** | 2025-05-28 |  |
| **[VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models](http://arxiv.org/abs/2505.19684v2)** | 2025-05-28 |  |
| **[Privacy-preserving Prompt Personalization in Federated Learning for Multimodal Large Language Models](http://arxiv.org/abs/2505.22447v1)** | 2025-05-28 | Under Review |
| **[CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction](http://arxiv.org/abs/2505.22304v1)** | 2025-05-28 | <details><summary>ACL 2...</summary><p>ACL 2025 main conference</p></details> |
| **[Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models](http://arxiv.org/abs/2505.22271v1)** | 2025-05-28 | Under Review |
| **[Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation](http://arxiv.org/abs/2505.22222v1)** | 2025-05-28 |  |
| **[CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling](http://arxiv.org/abs/2409.19291v3)** | 2025-05-28 |  |
| **[Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts](http://arxiv.org/abs/2505.12363v3)** | 2025-05-28 | <details><summary>In ve...</summary><p>In version 1, Hidetoshi Shimodaira was included as a co-author without their consent and has been removed from the author list</p></details> |
| **[Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning](http://arxiv.org/abs/2505.22095v1)** | 2025-05-28 |  |
| **[Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation](http://arxiv.org/abs/2505.21956v1)** | 2025-05-28 |  |
| **[MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering](http://arxiv.org/abs/2405.11985v4)** | 2025-05-28 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 findings</p></details> |
| **[Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model](http://arxiv.org/abs/2505.13062v3)** | 2025-05-28 | <details><summary>Accep...</summary><p>Accepted by Interspeech 2025</p></details> |
| **[Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task](http://arxiv.org/abs/2505.21850v1)** | 2025-05-28 | <details><summary>Accep...</summary><p>Accepted at ACL Findings</p></details> |

